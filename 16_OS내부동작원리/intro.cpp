/*
단편화란 무엇인가요?
멀티 프로그램을 지원하는 OS에서는 메모리상에 동시에 여러 프로세스가 실행됩니다.
이 때 이러한 프로세스 이미지들이 메모리에 로드되어 실행하다가 프로세스의 종료나 스와핑에 의해
메모리에서 다시 내려가기도 하는데 반복되면 메모리가 연속적으로 사용되지 않고 중간중간 자투리 구간이 생김.
이런 구간이 다른 프로세스 이미지를 수용하기에 크기 못하면 낭비되는데 이러한 현상을 단편화.

페이징이란 무엇인가요?
CPU는 프로그램을 수행할 때 한번 읽은 코드나 데이터가 있으면 다음 번에도 그 근처의 코드나 데이터를 읽을
가능성이 높다는 것이 실험적으로 밝혀져 있습니다.
이런 통계적 사실(공간 구역성)에 근거해 매 번 인스트럭션이나 데이터를 하드디스크에서 읽어오는 대신
한번에 일정한 크기로 덩어리를 읽어오는 방식이 페이징.

01 프로세스 vs 메모리
멀티 프로그래밍 OS상에서는 여러 프로세스들이 동시에 시스템에서 돌아가려면 각 프로세스가
서로 정해진 규칙하에서 메모리나 I/O 장치 등을 혼자서 독점하지 않고 사이좋게 나누어야 합니다.
가장 중요한 자원은 CPU와 메모리.
일반적으로 CPU는 적지만 시스템 전체 스레드의 개수는 훨씬 많았다.
이를 OS가 스케쥴링이라는 것을 통해 해결.
프로그램이 실행되려면 일단 프로그램의 코드와 데이터가 메모리로 올라와야 합니다.
그리고 프로그램이 실행 중에도 동적으로 더 메모리를 필요로 할 수도 있습니다.
프로그램은 최소 자신의 코드와 데이터 사이즈만큼 메모리를 사용해야 하는데, 멀티 프로그래밍 OS에서는
동시에 여러 개의 프로그램이 돌아가므로 메모리 역시 구분해서 사용해야 합니다.
(파워포인트와 워드가 동시에 사용되면 파워포인트는 0~1000, 워드는 1001~2000 이런식으로)
하지만 응용 프로그램을 개발하는 시점에서는 그 프로그램이 돌아갈 환경에 대해 전혀 가정할 수 없습니다.
도스 시절에는 특히 보호모드라는 것을 사용하지 않으면 640KB라는 제약이 있어 그 안에서만 프로그램을 실행.
많은 데이터를 필요로 하는 프로그램들은 메모리 한계를 극복하기 위해 개발자가 프로그램 구조를 잘 조절해야 했다.
게임 같은 경우 모든 이미지를 다 로드하는 대신 매 스테이지마다 이미지를 로드한다던가,
워드프로세서에서는 눈에 포이는 페이지의 데이터만 메모리에 유지하면서 페이지 스크롤 할 때마다 갱신한다든지
하는 식으로 적절한 메모리 관리를 개발자가 도맡아서 했습니다.
간혹 프로그램 코드 자체의 사이즈가 커지는 경우는 더 힘듭니다.
데이터는 필요에 따라 로드할 수 있지만 코드의 경우는 과정자체가 필연적이므로 복잡해진다.
프로그램이 실제로 메모리상에서 어떤 형태로 실행되는지 완전히 꿰뚫고 있는 방식을 Overlay.
하지만 최신 OS에서는 프로그램이 실행될 환경에서 메모리가 얼마나 있는지, 또 다른 프로그램들과 함께
메모리를 공유하기 위해 메모리를 어떻게 나눠야 하는지 등에 대해 신경을 쓰지 않아도된다.
OS덕에 프로그램은 컴퓨터에 메모리 상관없이 32비트 컴퓨터에선 4GB라는 메모리 공간을 활용할 수 있었다.
(다소 제약이 있습니다. 직접 메모리의 주소를 지정해서 거기에 데이터를 읽거나 쓰는 것은 위험.
항상 OS에서 제공하는 API를 사용해 메모리를 할당받거나 프로그램상에서 변수를 선언해 사용)
그리고 공간이 다른 프로그램에 의해 침범될까봐 걱정할 필요도 없습니다.
왜냐하면 모든 프로그램은 모두가 각각 자신의 4GB메모리를 할당받아 사용하기 때문.
그리고 각 메모리들이 모두 0번지부터 시작해 주소가 서로 겹치는데, 서로의 영역을 침범하지 않는다.
이렇게 각 프로그램마다 받아 사용하는 고유의 메모리를 가상메모리(Virtual Memory).
가상 메모리가 4GB로 제한되는 것도 CPU가 32비트이기 때문.
32비트 CPU에서는 모든 레지스터가 32비트로 이루어져 있고 이는 Fetch 인스트럭션 주소를 지정하는 PC도 마찬가지.
PC가 32비트이다보니 결국 32개의 비트로 표현 가능한 범위가 0~4GB이기 때문에 제한.
64비트 컴퓨터라면 2^64의 가상메모리를 하나의 프로그램이 사용할 수 있는 것.

02 프로그램이 실행되기까지
소스코드를 작성하고, 컴파일러가 이를 컴파일해서 실행 파일을 생성하고, OS가 실행파일을 로드하고
메모리에 적재해서 실행하는 과정.
소스코드를 타이핑하고 Build를 하면 .exe의 실행 파일이 생성됩니다.
코드는 컴파일 과정과 링킹(linking)이라는 과정을 거쳐 실행 파일이 되는 것.

#include <stdio.h>
int Add(int a, int b) {
	return a + b;
}
main() {
	int Sum = Add(3, 5);
	printf("3 + 5 = %d\n", Sum);
}                                            ┌>|mov ax, a+b|─add
          ┌>|mov ax, a+b  |─add   |...   |   └─|call add   |┐main
		  └─|call add     |┐main  |printf|   ┌─|call printf|┘
			|?? printf ?? |┘      |...   |   └>|    ...    |─printf
소스코드 -----> .obj -----> .obj + .lib -----> .exe
        컴파일                링킹(링커)
우선 소스파일을 컴파일러가 해석합니다.
그리고 타겟 CPU에 따라 적절한 인스트럭션을 생성합니다.
컴파일러는 위에서부터 차례대로 소스를 훓어가면서 제일 먼저 나온 add라는 함수에 대해 코드를 생성할 것.
그리고 main함수가 나타나면 main함수의 코드를 생성.
main에서 add라는 함수를 호출하고 결과값을 가지고 다시 printf라는 함수를 호출.
코드를 생성하기 위해 컴파일러는 지금까지 코드 중 add라는 함수가 존재하는지 확인.
add함수는 같은 소스 파일 안에 있어 컴파일러는 이미 add함수에 대한 코드를 생성하고 함수를 호출.
다음엔 컴파일러가 printf를 호출하는 루틴을 만납니다.
우선 컴파일러는 printf라는 것이 무엇인지 검사합니다.
검사과정에서 #include <stdio.h>에 기술된 stdio.h라는 파일도 같이 검사.
stdio.h라는 파일을 열어서 확인하면 printf라는 함수가 정의되어 있습니다.
하지만 stdio.h 안에는 단순히 함수의 prototype만 정의되어 있고 실제 printf를 구현하는 내용은 없습니다.
여기서 컴파일러는 중요한 결정을 합니다.
printf라는 함수를 호출하는 루틴을 만났는데, 이 함수가 존재하는 것인지 검사.
일단 형이 정의되어 있는 것을 확인했으므로 printf를 호출하는 부분에서 인자 등이 정의된 형식에 맞는지 확인.
이상이 없다면 컴파일을 마치게 됩니다.
문제는 printf가 문법적으로 맞게 호출이 되었지만 call을 생성하려해도 구현되어 있지 않아 
call 인스트럭션의 타겟주소를 생성할 수 없다.
하지만 컴파일러는 printf가 정의는 되어있으므로 다른 소스파일이나 라이브러리에 구현되있을 것이라고 믿고
call인스트럭션의 타겟 주소 생성을 뒤로 미루게 됩니다.
대신 그 부분이 printf라는 함수를 호출하고 있다는 체크만 해둡니다.
이렇게 컴파일러에 의해 성성된 파일이 목적파일이라 부르는 .obj입니다.
목적 파일만으로는 완전한 실행 코드가 아닙니다.
아직 printf라는 함수를 호출하는 부분이 생성되지 못했기 때문.
남은 부분은 링커(linker)라는 것이 맡게 됩니다.
링커는 컴파일러가 생성한 목적 파일과 따로 지정된 라이브러리 파일들을 모두 검사합니다.
그리고 이들을 몽땅 합쳐서 최종적으로 실행 파일을 생성하는 것.
링커는 .obj파일과 .lib파일을 모두 검사해 합치고 최종적으로 .exe라는 실행 파일을 생성하는 것.
이 과정에서 링커는 컴파일러가 목적 파일에 체크해 둔 부분을 완성합니다.
링커는 프로젝트 상의 모든 목적파일과 지정된 라이브러리를 검사해서 함수가 존재하는지 확인하고
존재한다면 그 부분을 실행파일에 복사해오고 그 복사된 주소를 호출하도록 체크한 부분을 채워넣는 것.
결국 링커는 add와 main이라는 함수의 코드는 .obj파일 안에서 가져오고
printf의 코드는 .lib 안에서 가져오고 컴파일러가 main함수 안에 체크해 둔 부분을 찾아 최종적으로 
printf의 코드가 있는 곳을 호출하도록 코드를 완성.
전역 변수 등을 참조할 때도 마찬가지입니다.
extern int VAR이라고 선언해주면 컴파일러는 소스파일을 컴파일하면서 VAR변수를 위한 공간을 실제로 생성하는 대신
VAR를 참조하는 곳마다 체크해둡니다.
만약 extern이 아닌 실제로 int VAR라고 선언된 파일을 컴파일하면 VAR변수를 위한 공간을 마련합니다.
컴파일러가 abc.obj와 zyx.obj라는 목적 파일을 생성해두면 링커가 최종적으로 모든 목적 파일과 지정된
라이브러리 파일을 검사하고 취합합니다.
링커는 abc.obj와 zyx.obj의 코드를 합쳐 최종 실행 코드를 생성한 후에 VAR변수를 참조하기 위해
체크된 부분마다 합쳐진 코드상의 VAR변수 주소를 참조하도록 수정하는 것.
링커가 하는 이런 작업을 링킹(Linking)이라고 합니다.

add와 printf함수를 호출하는 부분은 call이라는 인스트럭션으로 번역될 것입니다.
call은 다음에 지정된 타켓 주소로 점프하는 명령.
문제는 타겟 주소를 결정하는 것.
만약 시작주소를 500이라하면 call add는 call 500, call printf는 call 500+alpha.
만약 프로그램이 메모리로 로드되는 주소가 0번지라면 call add는 call 0, call printf는 call 0+alpha.
결국 프로그램이 메모리상에 로드되는 위치에 따라 링커가 주소를 결정해서 코드를 수정해야 합니다.
즉, OS가 프로그램을 로드할 때 고정된 메모리 위치에 로드하고 링커가 그 고정 주소를 알고 있다면
이런 식으로 절대 주소를 생성해 낼 수 있습니다.
사실 add함수를 호출하는 부분 역시 절대주소로 지정되려면 결국 링커가 결정할 수 밖에 없습니다.
이 부분은 컴파일 옵션에 따라 달리지는 부분으로 직접 절대시작주소를 컴파일러가 지정하게 할 수도 있고,
아니면 printf의 호출처럼 링커에게 이 작업을 맡길 수도 있습니다.
도스에서 실행파일은 exe확장자와 com확장자가 있는데 com확장자를 가지는 실행파일은 항상 절대주소를 사용.
(80x86 CPU에선 세그먼트라는 개념을 사용해 코드와 데이터 등을 구분해서 사용)
com파일은 항상 0x100번지라는 절대주소에서 시작해서 64KB(한 세그먼트크기) 크기 이내로 작성해야 했다.
따라서 com파일에서는 직접 사용자가 점프할 절대주소나 데이터가 위치한 메모리의 절대주소를 지정해 사용할 수 있었다.
(실제로드되는 메모리 위치는 달라질 수 있지만 세그먼테이션이라는 개념을 통해 세그먼트 안에서는 절대주소처럼)
하지만 이런 식으로 절대 주소를 지정하게 되면 필연적으로 발생하는 문제들.
아주 작은 임베디드 시스템의 펌웨어를 작성하는 경우는 절대주소 지정방식도 상관없습니다.
OS가 없는 임베디드 시스템에서는 작성한 코드가 전체 하드웨어를 독점하여 사용하기 때문에
오히려 절대 주소 체계를 사용해서 작성해야만 합니다.
만약 전원이 들어오면 100번지부터 프로그램을 수행하는 임베디드 시스템이 있다면 그에 맞추어 롬이나 플래시메모리 등에
100번지부터 코드가 오도록 적절히 코드를 다운로드 해야(롬을 구워야)합니다.
그리고 그 코드는 절대 주소 체계를 사용해야 한다.
하지만 일반적으로 OS가 있는 환경에서는 고정 주소를 사용하는 것이 힘들어 집니다.
임베디드 시스템의 펌웨어는 별도의 로딩 과정 없이(재배치. 부트로더같은 것을 사용하기도) 롬이나 플래쉬 메모리에
직접 바이너리를 물리적으로 적재시키는 반면, OS가 있는 경우는 일반적으로 파일 시스템이라는 것이 있고
(일부 임베디드용 OS는 파일 시스템없이 OS커널과 응용 프로그램이 함께 링킹되어 하나의 바이너리를 형성하기도)
파일 시스템을 통해 동저긍로 실행파이너리 파일을 로드하기 때문.
OS자체도 하나의 프로그램 코드이므로 메모리에 상주하게 되고, 이 코드나 데이터 크기가 동적으로 변하는 경우든지
(디바이스 드라이버를 동적으로 로드하거나 해서) 혹은 OS버전업이 되어 사이즈가 바뀌는 경우에는 응용 프로그램이
로드되는 위치 또한 거기에 맞춰 변할 수밖에 없기 때문.
이럴 경우 응용 프로그램이 절대 주소 체계를 사용한다면 재컴파일과 링킹을 통해 변경된 시작주소를 바꿔야한다.
게다가 OS가 멀티 프로그래밍을 지원하면 문제가 더 심각.
여러 개의 프로그램이 동시에 메모리에 로드되어야 하는데, 미리 결정해 둘 수 있는 상황이 아니므로
상황에 따라 로드된 응용 프로그램의 시작 주소가 가변적일 수 밖에 없다.
따라서 고정 주소를 가지도록 컴파일(링킹)된 응용 프로그램은 사용을 할 수 없다.
이런 불편함을 없애기 위해 생각해 낸 방식이 재배치(Relocation) 및 
적재 시간 주소 바인딩(Load Time Address Binding)이라고 부르는 것.
우선 주소 바인딩은 주소를 코드와 결합시키는 것을 의미합니다.
앞에서 call인스트럭션을 통해 다른 함수를 호출하려 했는데 이 때 이 호출될 함수의 주소를 언제 결정하는가 하는
문제가 있기 때문에 주소 바인딩이라는 용어가 생김.
링커가 절대주소를 생성하는 과정을 컴파일 시간 주소 바인딩(Compile Time)
즉, 컴파일(+링킹)하는 과정에서 주소가 결정되버린다는 의미.
그래서 call add부분이 call 500같이 절대적인 숫자로 결정나는 것.
컴파일 시간 주소 바인딩의 경우 구조가 간단하지만 위에처럼 문제점을 갖고 있습니다.
임의의 프로그램이 동시에 로드할 수 없으며, 항상 고정된 주소에만 로드해야하기 때문에
조금만 환경이 변해 로드 지점이 달라지면 다시 컴파일해야 한다는 결정적인 단점.
이런 단점에도 불구하고 도스 시절에는 com파일이나는 형태로 이 구조를 지원.
이를 해결한 것이 적재 시간(Load Time) 주소 바인딩.
프로그램을 메모리로 로드하는 시점에서 주소를 결정하자는 것.
컴파일하는 과정에서 컴파일러나 링커가 메모리 주소를 필요로 하는 인스트럭션의 주소를 결정하는 것이아니라,
단지 이런 부분에 표시해두고 실제로 이 프로그램이 실행되기 위해 메모리로 로드되는 시점에 이 주소를 확정
짓도록 코드를 수정하는 방법.
컴파일러가 printf의 주소를 결정하지 못하고 표시만 해두면 후에 링커가 이를 보고 주소를 결정해서
코드를 완성시키는 것과 같다.
이번엔 링커가 주소를 결정하는 것이 아니라 OS의 프로그램로더가 프로그램을 메모리로 로드하는 시점에 이를 결정.
이를 위해 프로그램은 재배치가 가능한 형태로 컴파일되어 있어야 합니다.
즉 컴파일러는 메모리 주소가 필요한 인스트럭션에서 절대주소를 생성해내는 대신 0번지를 기준으로 한
상대적인 주소만 생성하고 대신 실행 파일의 헤더 등에 이런 인스트럭션이 어디에 위치하는지를 표시.
그러면 로더가 프로그램을 로드하면서 로드된 시작 지점의 주소를 이들 상태주소에 더해 최종적인 타겟주소를 완성.
헤더:재배치가 필요한 코드의 위치를 모두 기록
     |    헤더   |
100B─|mov ax, a+b|─add               200번지로 로드(Load)     100B─|mov ax, a+b|─add
150B┌|call 0     |┐main                -------->             150B┌|call 200   |┐main
	└|call 250   |┘                                              └|call 250   |┘
 70B─|    ...    |─printf                                     70B─|    ...    |─printf
call은 프로그램 시작 지점으로부터의                            헤드를 참고해서 로드된 메모리의 시작주소
상대 주소만 기록                                              200번지를 기준으로 재배치함.
                                                             이 때 헤더는 로드할 때의 정보로만 활용하고
															 실제 메모리 상에 로드되지는 않음.
call 같이 메모리 주소가 필요한 인스트럭션은 우선 프로그램이 0번지를 기준으로 로드된다고 가정하여 프로그램 시작
지점으로부터의 상대적인 위치만을 기록합니다.
그리고 헤더를 만들어 이 헤더 안에 이러한 재배치가 필요한 인스트럭션의 위치를 기록해 둡니다.
그러면 실제 프로그램이 실행되기 위해 메모리로 로드되면서 OS의 로더는 이 프로그램 파일의 헤더를 살펴보고
재배치가 필요한 곳마다 수정을 가하게 됩니다.
가령 로드되는 메모리 주소가 200번지라면 모든 재배치가 필요한 인스트럭션의 타겟 주소에 200을 더해주는 것.
적재 시간에 주소 바인딩이 일어나면 프로그램을 임의의 메모리 주소로 로드할 수 있다는 장점.
이렇게 되면 프로그램을 여러개 로드해서 실행하는 멀티 프로그래밍 OS에서도 문제가 없다.
현재 메모리 상황에 따라 적절히 빈 메모리 공간을 찾아 해당 주소로 코드를 재배치해서 로드하면 됨.
여기서 한단계 업그레이드된 버전은 실행시간 주소바인딩(Execution Time Address Binding)
주소의 결정이 최종적으로 CPU가 해당 인스트럭션을 막 실행시키는 시점에서 결정나는 것.

03 멀티 프로그램을 위한 메모리 관리
멀티 프로그래밍을 지원하는 OS에서는 여러 개의 프로세스가 함께 돌아가야 합니다.
한 프로세스가 일방적으로 CPU를 독점하는 것이 아니라 여러 개의 프로세스가 잠깐씩 번갈아 실행되어
동시에 여러 프로세스가 돌아가는 것처럼 느끼게 하는 것.
이 과정에서 필수적으로 프로세스 간의 문맥 전환이 일어나고 문맥 전환에는 많은 비용이 듭니다.
CPU의 실행 권한이 넘어갈 때, 재개하려면 실행의 연속성을 보장하기 위해 프로세스의 많은 정보를 보관해야 합니다.
프로세스의 레지스터 값이나 메모리 값 모두 보존되어야 한다.
만일 메모리가 매우 크면 비교적 빠르게 진행될 수 있지만 둘 중 하나의 정보만 수용할 수 있을 정도로 작다면
OS는 문맥 전환과 함께 스와핑(Swapping) 과정을 거쳐야 합니다.

스와핑이란 프로세스의 문맥 정보를 메모리에서 보조기억장치로 옮겨둔 다음, 새로 실행되는 프로세스의 문맥 정보들을
다시 하드디스크에서 읽어오는 것.
하드디스크로 프로세스의 문맥 정보를 옮기는 것을 Roll Out이라하고,
반대로 재개되는 프로세스의 문맥 정보를 읽어 메모리로 가져오는 것을 Roll In.
스와핑을 지원하는 OS라면 이론적으로 프로세스 개수에 문제가 없습니다.
하지만 롤인과 롤아웃하는데 문맥 전환 간격 보다는 커서 동시느낌이 아니다.
그래서 대부분의 시간을 스와핑하는데 쓰고 정작 프로그램을 돌리는데 적은 시간을 할애해버린다.
이를 해결하기 위한 가장 쉬운 해결책은 대용량의 메모리를 사용하는 것.
그리고 한 프로세스가 모든 메모리를 차지하는 것이 아닌, 메모리가 가득 찰 때까지 가능한 모드 프로세스를
다 메모리에 보관하고 스와핑하지 않는 것.
부족하면 그 때 가서 새로 생성된 프로세스에게 가용 메모리 공간이 생길 때까지 기다림.
만약 여기서도 스와핑을 통해 문맥 전환을 하면 결국 똑같이 문제.
이런 방식을 다중 분할 할당(Multiple-Partition Allocation).

메모리
|   OS   |                        |   OS   |                           |   OS   |
|프로세스1|\_300                   |프로세스1|\_300                     |프로세스1|\_300
|프로세스2|\_400    프로세스2종료   |  빈공간 |\_400     프로세스4실행    |프로세스4|\_400
|        |          --------->    |  빈공간 |           ---------->    |  빈공간 |
|프로세스3|\_700                   |프로세스3|\_700                     |프로세스3|\_700
|  빈공간 |\_900                   |  빈공간 |\_900                     |  빈공간 |\_900
          \_1000                             \_1000                              \_1000
만일 프로세스2가 끝나기 전에 프로세스4가 실행되려 한다면 앞의 프로세스4는 크기가 확보될 때까지
누군가가 종료되어 공간이 날 때까지 기다려야 할 것.
프로세스2나 3이 종료되면 충분한 공간이 생기지만 프로세스1은 종료되어도 100바이트여서 부족합니다.
마지막 끝에 있는 100바이트와 프로세스1의 100바이트를 합쳐 200바이트지만 공간이 나누어져 실질적으로
쓸모없는 공간이 되버리는 것을 단편화(Fragmentation). 특히 외부 단편화(External Fragmentation)

일반적인 메모리 사이즈는 충분히 여러 개의 프로세스를 수용할 수 있을 정도로 아주 큽니다.
그런데 한계가 있고 프로세스 수가 늘어나면 다른 프로세스가 못올라올 수도 있다.
뒤로 갈수록 단편화가 심해지면 메모리 낭비가 많아져 수용가능한 프로세스 수가 더욱 적어짐.
이런 외부 단편화 문제를 해결하기 위해선 빈 공간을 활용하는 몇 가지 방법이 있고,
자잘한 빈 공간들을 몰아서 큰 공간을 만드는 압축(Compaction)방법도 있다.
빈 공간을 찾는 방법으로는 가장 먼저 발견되는 큰 공간을 사용할 것인지, 아니면 전체 빈공간 중에 새
프로세스의 크기와 가장 비슷한 곳을 활용하는 등 몇가지 방법이 있다.
압축 역시 가장 확실한 방법이긴 하지만 압축을 하려면 현재 메모리상에 있는 프로세스들을 옮겨 연속되도록
붙여야 하는데, 컴파일 타임, 적재 시간 주소 바인딩으로는 해결하기 어렵습니다.
두 방법 모두 프로세스가 실행되기 전에 메모리를 참조하는 인스트럭션들의 타겟 주소값이 결정나버려
실행 중에 있는 프로세스들이 옮겨지면 엉뚱한 메모리를 참조하게 되는 것.

실행시간 이전에 주소 바인딩이 된 경우 - 압축 후 엉뚱한 루틴을 호출
|     프로세스1     |                      |     프로세스1     |
|                  |         압축 후       |      printf      |
|      printf      |\_0x800   ----->      |     프로세스2     |\_0x800
|     프로세스2     |                      |call printf(0x800)|
|call printf(0x800)|
프로세스2가 printf루틴을 호출하기 위해 call인스트럭션이 사용되었는데, 이 때 주소 바인딩이 실행 시간 이전에
(컴파일 시간 혹은 적재 시간)이루어지고 그 주소가 0x800번지라면 압축 후에는 문제가 될 것.
압축 후엔 0x800번지에는 엉뚱한 코드가 존재하지만 프로세스2는 여전히 0x800으로 점프.
그래서 필요한 것이 실행시간 주소 바인딩(Execution Time Address Binding).
call과 같은 인스트럭션의 타겟 메모리 주소가 실제 그 인스트럭션이 CPU에 의해 폐치되기 바로 직전에 결정.

실행 시간에 주소 바인딩이 이루어진 경우 - 압축 후에도 정상적으로 printf를 호출.
|     프로세스1     |                      |     프로세스1     |
|                  |         압축 후       |      printf      |\_0x300
|      printf      |\_0x800   ----->      |     프로세스2     |
|     프로세스2     |                      |*call printf(0x0) |
|*call printf(0x0) |
call(0x800+0x0)으로 패치되어 CPU가 실행     call(0x300+0x0)으로 패치되어 CPU가 실행
이를 구현하기 위해 컴파일러(혹은 링커)는 call printf부분의 코드를 생성할 때 이 프로세스가 항상
0번지를 기준으로 시작된다고 전제하고 타겟 주소를 생성합니다.
그러면 printf루틴인 최종 컴파일 결과 코드의 제일 첫 부분에 위치하게 되었으므로 이를 호출하는 call printf부분이
call 0x0으로 기술.
그리고 실제 이 코드가 CPU로 패치되는 시점에서 프로세스2가 메모리에 위치한 시작주소와 함께 더해져 최종주소 결정.
사실 이러한 실행시간 주소바인딩(실시간 주소 바인딩)은 OS의 힘만으로는 구현하기 힘듭니다.
OS가 이를 해결하려면 매 인스트럭션 수행 때마다 OS로 다시 제어권이 넘어가 수행되고 다음 인스트럭션의
주소 바인딩을 위해 인스트럭션을 수정해서 다시 메모리에 저장해야 하는데, 그 경우 속도가 떨어지게 됩니다.
따라서 이런 경우 하드웨어적인 지원이 필수적인데, 최근의 고성능 CPU들은 대부분 이런 실행시간 주소 바인딩을
지원하기 위한 별도의 메커니즘을 내장하고 있습니다.
예를 들어 메모리를 참조하는 인스트럭션은 CPU가 패치할 때 그냥 읽어가는 것이 아니라 타겟 주소를 항상
특정한 레지스터 값과 더해서 읽는 것(재위치레지스터).
그러면 각 프로세스는 실행될 때 필요한 자신의 시작 주소를 문맥이 전환이 될 때마다 재위치 레지스터에
저장해 놓는 것만으로 모든 메모리 주소를 참조하는 인스트럭션이 정상적인 메모리를 참조할 수 있다.

실행시간 주소 바이딩이 이루어진 경우 - 메모리 상의 코드와 CPU가 패치한 코드가 다르다.
      |   OS   |
 300_/|프로세스1|
 400_/|프로세스2| --> 프로세스2가 활성화 될 때 시작주소 400을 레지스터에 세팅.   --------------------------┐
 500_/|        | <-- 최종적으로 500번지로 점프 <--|CPU|<--  400+100=CPU가 패치하게 되는 코드는 call 500 <-┘
      |call 100|(실제 메모리 상의 코드)
 700_/|프로세스3|
 900_/| 빈 공간 |
1000_/
결국 이런 식의 실행시간 주소 바인딩을 하려면 컴파일러가 우선 이에 맞게 0번지에서 시작하는 주소값으로 
컴파일해야 하고 OS는 프로세스가 활성화할 때마다 해당 프로세스의 시작주소를 재위치 레지스터에 저장하고,
CPU는 인스트럭션을 패치할 때 메모리 참조 인스트럭션인 경우 항상 주소 값을 재위치 레지스터의 값과 더해서 가져옴.
하지만 여전히 문제가 있습니다.
압축을 해도 어느 시점에서 압축할지 고민이고, 결국엔 프로세스 수가 늘어남에 따라 메모리가 가득찰 것이다.
그러면 결국 그 이후에 생성되는 프로세스는 앞의 프로세스가 종료되어 자신이 들어갈 공간이 생길 때까지
무한정 대기한다.
하지만 우리는 아무 문제 없이 윈도우상에서 많은 창을 띄워놓고 작업을 할 수 있습니다.
그 이유는 페이징이라는 혁신적인 방법.

04 페이징
멀티 프로그램을 구현하기 위한 한 방법이 바로 다중 분할 할당이었습니다.
OS가 스케쥴링이라는 것을 통해 각 프로세스가 조금씩 실행될 수 있도록 하는 것이 최우선이지만,
매 문맥 전환 때마다 스와핑하는 것은 너무 비효율적이므로 그나마 효율적으로 하기 위한 것이 다중 분할 할당.
하지만 여전히 메모리가 가득 찼을 때는 스와핑을 한다든가 후속 프로세스가 대기해야 한다는 문제점.
그리고 외부 단편화가 발생한다는 치명적인 문제.

단편화를 해결하기 위해 연구 결과 프로그램에는 다행히 구역성(Locality)라고 하는 성질이 있다.
한 함수 안에서 쓰이는 지역 변수들은 인접한 공간에 위치하게 되므로 계속 비슷한 영역 안에서 데이터를 읽거나 쓴다.
무엇보다 모든 프로그램은 순차적으로 실행됩니다.
위에서 아래로 차례대로 실행하도록 설계되어 있는 것.
이런 성질이 구역성이고 공간구역성(Spatical Locality)와 시간구역성(Temporal Locality)가 있다.
공간구역성이란 어떤 프로세스가 메모리의 한 곳을 일단 액세스하기 시작하면 그 주변 데이터도 곧이어 사용될
확률이 높다는 것을 의미.
즉, 순차적으로 실행되는 코드 역시 메모리에서 인접한 인스트럭션이 읽혀오므로 공간구역성을 가진다.
배열로 선언된 변수들은 대부분 루프를 돌면서 전체나 일부를 검사하게 되는데 이런 성질을 공간구역성.
공간적으로 인접한 메모리가 아니라, 시간적인 관점에서 한번 액세스된 데이터는 곧이어 다시 액세스될 확률이
높다는 것이 시간 구역성.
루프를 돌 때 순회 변수를 선언하고 변수가 저장된 메모리는 시간적으로 가까운 시기에 걸쳐 여러 번 읽힌다.
함수가 호출되면 스택에 지역변수들이 잡히고, 스택 영역은 적어도 함수 안에서 계속 액세스하므로 시간구역성.
이를 다시 말하면 한 프로세스는 비슷한 구역에 있는 데이터를 비슷한 시간대에 몰아서 액세스하는 경향이 있다.
이런 구역성을 적극활용하면 굳이 프로세스 전체의 코드나 데이터를 다 메모리에 올릴 필요가 없다는 것.
즉, 각 프로세스마다 현재 수행되고 있는 코드나 액세스되고 있는 데이터 근방의 일정 크기의 데이터만큼만
메모리에 올리면, 그 안에서만 액세스가 일어나므로 굳이 많은 메모리가 필요없는 것.
이러면 실제 수용 가능한 프로세스보다 훨씬 많은 수의 프로세스를 동시에 메모리에 올릴 수 있다.
아무리 공간구역성이 있어도 언젠가는 다른 구역의 데이터나 코드를 액세스하는 시점이 온다.
그때도 공간구역성을 활용하여 프로세스 전체를 스와핑하지 않고 액세스가 발생한 일정한 작은 영에 한해서만.
그러면 스와핑 속도도 빨라지고, 한번 롤인해 메모리로 들어온 데이터들은 한동안 사용되므로 스와핑 주기도 길어짐.
그러면 프로세스 전체를 프로세스의 문맥 전환이 일어날 때마다 스와핑해야 하는 부담이 사라짐.
단편화문제는 프로세스마다 구역의 크기를 다르게 하지 않는다는 것.
구역의 크기를 일정한 크기로 나누어서 사용하면 외부 단편화가 발생하지 않습니다.

예를들어 구역의 크기를 4KB로 고정하고 물리적 메모리를 4KB단위로 차례대로 번호를 매긴다.
또한 프로세스의 코드와 데이터 전체를 합쳐 4KB단위로 쪼갠다.
프로세스에서 쪼갠 4KB단위의 구역을 '페이지', 실제 메모리에서 쪼갠 4KB단위구역을 '프레임'.
    프로세스  메모리
4KB 페이지0   프레임0 4KB
4KB 페이지1   프레임1 4KB
4KB 페이지2   프레임2 4KB
4KB 페이지3   프레임3 4KB
3KB 페이지4   프레임4 4KB
             프레임5 4KB
			 프레임6 4KB
			 프레임7 4KB
메모리는 딱맞춰 8개의 프레임으로 나누어졌지만 프로세스는 4KB 4개와 3KB 하나의 페이지.
PC의 전원이 들어오고 OS가 실행되고 피피티를 실행하면 OS는 피피티 실행파일에서 코드랑 데이터를 메모리로 
로드하지 않고 프로세스라는 형식만 갖춰놓고 있습니다.
OS는 피피티프로세스로 문맥 전환을 하고 이런 사실을 모르는 CPU가 피피티 프로세스의 시작 코드를 실행하기 위해
PC레지스터가 가리키는 메모리 주소에서 인스트럭션을 패치해 오게 됩니다.
이 때 CPU는 곧바로 메모리에서 값을 읽어오는 대신 '메커니즘'에 의해 지금 패치하려는 메모리 주소에 정상적으로
프로세스의 코드나 데이터가 올라와 있는지를 살펴봅니다.
여기선 피피티의 프로세스만 생겨있고 실제 코드나 데이터가 메모리로 로드된 상황이 아니어서 CPU는 에러를 발생.
이 에러를 페이지 폴트(Page Fault)라고 부르고 일종의 인터럽트로 인터럽트가 걸리면 CPU는 현재 수행하던
것을 멈추고 인터럽트 종류에 따라 이를 추리할 수 있는 코드가 있는 주소로 점프.
그리고 이 페이지 폴트를 처리할 코드는 OS자신이 됩니다.
OS는 자신이 로드되면서(부팅하면서) 이런 작업을 미리 해놓습니다.
페이지폴트 인터럽트가 걸리면 CPU가 이 페이지 폴트를 처리할 수 있는 코드를 점프하도록 미리 세팅을 해두고
이렇게 페이지 폴트가 발생하면 자동으로 그 코드를 실행하는 것.
피피티가 실행되면서 첫 번째 페이지폴트가 발생해서 OS의 페이지 폴트 처리 코드로 CPU는 점프.
이 코드가 수행하는 것은 필요한 페이지를 메모리로 로드하는 것.
가령 CPU가 실행하려면 피피티의 시작코드가 페이지3의 어딘가에 있었다면, OS는 페이지3에 해당하는 4KB를
메모리상에 쪼개진 프레임 중 한 곳으로 옮겨 옵니다.
그리고 이 페이지 폴트 루틴이 리턴하고 나면 CPU는 아까 패치하려다 실패한 걸 잊어버리고 하던 일을 계속.
즉, 아무 일도 없었다는 듯이 메모리에서 인스트럭션을 읽어오는 것.
하지만 이미 해당 페이지가 메모리로 로드된 상태이므로 실질적으로 CPU는 정상적인 인스트럭션을 패치할 수 있다.
정상적으로 수행한 CPU는 다음 코드를 수행하려하는데 페이지 폴트를 일으키지 않는다.
좀전에 페이지 폴트에 의해 읽어온 것이 4KB에 해당하는 한 페이지를 읽어왔기 때문에 지역성에 의해
CPU가 수행하려는 다음 인스트럭션도 그 4KB안에 포함될 가능성이 크기 때문.
점프하려는 곳이 다른 페이지 안에 있는 경우는 다시 페이지 폴트가 발생할 것.
발생하면 다시 OS의 페이지 폴트 처리 루틴이 실행되고 루틴에서는 폴트가 발생한 페이지를 읽어 메모리의
프레임 중 적절한 곳에 배치할 것.
그리고 CPU는 정상적으로 해당 인스트럭션이나 데이터를 액세스.
이런 식으로 미리 프로세스의 전체 코드, 데이터를 메모리로 로드하는 대신, CPU가 실제 읽어갈 때마다 페이지가
메모리상에 로드되었는지 여부를 검사하고, 없다면 로드시키고 다시 수행을 재개하는 방식을 요구페이징(Demand Paging).
즉, CPU가 읽어가려고 '요구'할 떄마다 페이지의 부재 여부를 확인해서 없으면 로드한다는 의미.

요구페이징을 사용했을 때 장점
1)다중 분할 방식보다 훨씬 많은 프로세스가 동시에 수행될 수 있습니다.
다장 수행에 필요한 코드나 데이터만 페이지 단위로 메모리로 올리기 때문에 훨씬 많은 프로세스가 메모리에
올라와 수행된다.
2)외부 단편화가 발생하지 않습니다.
메모리와 프로세스를 각각 4KB단위로 쪼개서 가져오므로 항상 메모리는 빈틈없이 꽉 채울 수 있게 됩니다.
물론 프로세스의 마지막이 꼭 4KB라는 보장이없는데 작은 페이지가 로드되는 경우는 조금 달라짐.
3KB면 메모리의 프레임에서 뒤의 1KB가 남는데 단편화이긴하나 구분해서 내부단편화(Internal Fragmentation).
메모리
페이지3 4KB
프레임1 4KB
페이지2 4KB
페이지4 3KB
빈공간  1KB  ─페이지가 프레임에 들어가면서 발생하는 1KB의 낭비 공간이 내부 단편화.
프레임4 4KB
프레임5 4KB
프레임6 4KB
프레임7 4KB
프로세스가 수행되다가 세 번의 페이지 폴트가 발생했고 그 결과로 페이지 3,2,4가 로드.
페이지4의 경우 3KB이다 보니 프레임3에 딱 맞지 않고 1KB가 남았다.
만일 또 페이지폴트가 발생해 다른 페이지가 프레임4로 로드되도 그 공간은 로드되지 않습니다.
항상 4KB단위의 프레임 시작 지점에 맞춰 로드되므로 결국 1KB의 공간은 낭비되는 것.
그럼에도 불구하고 이런 내부 단편화는 외부 단편화에 비해 정도가 미미합니다.
페이지 크기 자체가 전체 메모리에 비하면 무척 작고, 내부 단편화는 기껏해야 프로세스당 마지막 페이지 하나.
프로세스가 10개일 경우 확률적으로 한 프로세스 당 2KB의 내부 단편화가 발생해도 20KB낭비.
이런 식으로 페이지 단위로 나누어 로드함으로 인해 외부 단편화를 없앨 수 있고,
보다 많은 프로세스가 동시에 실행될 수 있으므로 훨씬 더 효율적인 시스템.

05 페이징을 활용한 가상 메모리
페이지 폴트가 발생하면 어느 프레임에 페이지를 로드해야할까?
페이지 순서대로 프레임을 채워나가면 페이징의 장점이 모두 없어집니다.
한꺼번에 전체를 로드하지 않았을 뿐 결국은 다중 분할 방식과 마찬가지로 한 프로세스가 필요한 공간 전체를
메모리에 확보하고 있어야 하므로, 외부 단편화도 그대로 발생하고, 수용 가능한 프로세스도 차이가 없다.
스와핑도 다른 프로세스가 들어오려면 그 프로세스에 필요한 공간을 다 확보하고 있어야 하므로
기존 프로세스의 페이지 하나만 롤아웃하는 것으로는 다른 프로세스가 로드될 수 없습니다.
오히려 중간 중간 페이지 폴트가 발생할 때마다 페이지를 로드하다보니 자주 딜레이가 생길 수 있습니다.
결론은 페이지를 임의의 프레임에 로드할 수 있어야 합니다.
그런데 CPU는 기본적으로 순서대로 수행하는데 페이지가 메모리상에 이리저리 배치되어 있으면 순차 순행이 불가능.
그래서 사람들이 생각한 것이 가상 메모리(Virtual Memory).
가상 메모리란 실제 물리 메모리 주소와 CPU가 읽고 쓰고 하는 메모리 주소가 1:1매치되는 것이 아니라,
중간에 어떤 룰을 정해서 CPU가 요구하는 논리적 주소와 실제 메모리의 물리적 주소를 변환하자는 발상.
메모리
페이지3 4KB
프레임1 4KB
페이지2 4KB
페이지4 3KB
빈공간  1KB  ─페이지가 프레임에 들어가면서 발생하는 1KB의 낭비 공간이 내부 단편화.
프레임4 4KB
프레임5 4KB
프레임6 4KB
프레임7 4KB
프로세스에서는 페이지 0~4가 순서대로 되어있었는데, 실제 메모리로 로드된 그림은 동떨어져 있고 순서도 3,2,4.
CPU가 페이지2에서 페이지4까지 한 번의 분기문도 없이 순서대로 실행해 왔다면 CPU입장에선 PC레지스터가
차례대로 증가만 해왔을 것.
하지만 실제 메모리상에는 페이지가 뒤죽박죽 나열되어 있으므로 메모리 내용을 그대로 가져오면 안된다.
이를 해결하기 위해 페이지 테이블(Page Table)을 마련해 실제 메모리 주소와 CPU가 읽으려하는 논리주소를 변환.
위 프로세스를 0번지부터 차례대로 놓여져 있다고 가정하고 CPU가 수행한다고 생각해보면
만일 CPU가 페이지4의 시작 부분에 있는 인스트럭션을 패치하려 한다면 이 주소값이 그대로 메모리로 들어가는 것이
아니라 중간에 페이지 테이블을 통해 변환된 값이 메모리로 이동합니다.
CPU는 프로세스가 0번지부터 놓여져 있다고 생각하므로 페이지4의 시작부분을 액세스하기 위해
4KBx4라는 주소값을 내놓을 것이지만 실제 메모리에는 4KBx3번지부터 페이지4가 로드되어 있으므로
16384라는 주소는 12288로 변환될 것.

최종적으로 알아야 하는 메모리의 주소는 크게 두 부분으로 생각.
페이지 크기와 프레임 크기가 4KB로 고정되어 있다고 가정하면 4KB단위로 쪼개진 프레임 중 몇 번째 프레임에,
그리고 그 프레임 안에서도 몇 번째 바이트에 원하는 데이터가 있는지를 찾아야 합니다.
한 프레임 안에서 몇 번째 바이트라는 것을 나타내기 위해 몇 비트의 정보가 필요한지 생각해보면
한 프레임은 4KB이므로 12개의 비트가 있으면 4096경우의 수를 나타낼 수 있다.
한편 몇 번째 프레임이냐 하는 것을 나타내기 위해 필요한 비트 수는 전적으로 메모리 크기에 달려있다.
메모리 크기가 32KB이고 8개의 프레임으로 나뉘어진다면 2^3이므로 3비트만 있으면 됩니다.
따라서 물리 메모리를 나타내기 위해서는 3+12=15비트가 필요합니다.
논리 주소의 경우를 생각해보면 논리 주소를 실제 메모리 주소를 나타내는 것이 아니라,
한 프로세스상에서 어느 페이지의 몇 번째 바이트(오프셋)에 위치해 있는가를 나타내야 합니다.
오프셋을 나타내기 위한 비트 수는 한 페이지 크기가 얼마인가에 달려 있는데, 페이지 수는 기본적으로
프레임 크기와 같이 4KB이므로 물리 주소에서처럼 12비트가 필요.
페이지 번호는 해당 프로세스가 몇 페이지로 이루어져 있는가에 달려있다.
총 5개의 페이지가 있으면 3비트만 있으면 충분합니다.
따라서 페이지 번호를 나타내기 위한 3비트 + 오프셋용 12비트를 합쳐 15비트가 필요.
그런데 3비트만으로는 최대 8개의 페이지만 지정할 수 있어 32KB크기의 프로세스밖에 돌릴 수 없다.
그래서 이 크기는 일반적으로 CPU의 처리 용량에 따라 결정합니다.
32비트 CPU인 경우 데이터 처리 단위가 32비트입니다.
레지스터의 크기도 32비트이고 ALU도 32비트 ALU이고, 내부적으로 총 32개의 비트가 동시에 처리된다는 얘기.
따라서 인스트럭션을 패치할 주소를 나타내는 PC레지스터도 32비트일 것이고 이 크기에 맞춰 프로세스의 크기를 결정.
즉 32비트 논리 주소 중 12비트는 4KB페이지 안의 오프셋을 나타내는데 사용하고, 나머지 20비트로 페이지 번호.
2^20 = 1048576개의 페이지를 나타낼 수 있고 각각 페이지가 4KB크기이므로 총 4GB의 프로세스를 액세스.

페이지 테이블이 어떻게 구성되어야 할까?
우선 페이지 테이블을 통해 우리가 얻고자 하는 것은 논리 주소상의 페이지 번호를 실제 메모리 상의 프레임
번호로 바꾸는 것.
페이지 크기와 프레임 크기가 같으므로 한 페이지는 그대로 한 프레임으로 맵핑.
따라서 오프셋 값은 변환 없이 그대로 사용할 수 있다.
페이지 테이블에서 페이지 번호를 통해 프레임 번호를 찾는 가장 쉬운 방법은 페이지 번호를 테이블의 인덱스 값,
테이블 상의 몇 번째 항목이냐 하는 것을 나타내도록 하는 것.
32비트 CPU의 경우 총 20비트가 페이지 번호로 할당되었으므로 1048576개의 항목을 가진 테이블을 만들고
논리 주소의 페이지 번호 값으로 이 테이블의 몇 번째 행인가 하는 것을 결정합니다.
그리고 그 행에는 실제 물리 주소에서 필요한 프레임 번호를 적어두는 것.
 인덱스     물리 주소의 프레임 번호
   0              10023
   1                8
1048675            5330
그리고 논리주소는
0000 0000 0000 0000 0001 0000 0000 0000 0011
             페이지 번호┘ └오프셋
이런 경우 페이지 번호가 10진수로 1이므로 테이블 상의 1번 인덱스를 찾습니다.
그리고 거기엔 8이라는 프레임 번호가 기재되어 있습니다.
따라서 CPU가 위와 같은 논리 주소를 액세스하면 실제 메모리상에서는 8번 프레임의 4번째 바이트를 액세스하는 것.
이런 식으로 페이지 테이블을 이용하면 프로세스의 어떤 페이지도 메모리 안의 임의의 프레임으로 맵핑할 수 있어
더 이상 메모리상에서 프로세스 페이지가 연속으로 존재할 필요가 없습니다.
또한 이 페이지 테이블을 각 프로세스마다 별도로 가지면 모든 프로세스는 메모리 상의 어떤 위치에라도
프레임 단위로 임의의 페이지를 옮겨 놓을 수 있습니다.
                                 메모리
프로세스1의 페이지테이블  ---> |프로세스1의 페이지3|
                             |프로세스2의 페이지1|
프로세스2의 페이지 테이블 ---> |프로세스1의 페이지1|
						     |프로세스3의 페이지1|
							 |프로세스1의 페이지5|
							 |프로세스2의 페이지6|
							 ...

하지만 2^20개의 항목을 지닌 페이지 테이블은 x1B를 해서  1MB의 크기를 갖습니다.
게다가 각 프로세스마다 페이지 테이블을 별도로 가지게 되므로 10개 프로세스면 10MB크기의 공간이 페이지 테이블.
이를 위한 해결책은 페이지를 크게 잡아놓는 것.
4KB였던 것을 4MB로 잡게 되면 4GB가지는 32비트 CPU에서도 4GB = 4MB x 1024이므로 1024개의 항목을 지닌 페이지 테이블.
실제로는 메모리의 프레임 크기도 4MB이므로 프레임 개수도 줄어들어 이를 위한 비트수도 줄어들어 
페이지 테이블 크기는 사실 1/1024보다도 더 줄어듭니다.
무작정 페이지를 크게 잡는다고 안될 것은 없습니다.
실제로 윈도우즈에서는 128MB이상의 물리 메모리를 가진 시스템에서는 윈도우즈 OS자신의 핵심 코드들을 메모리의
후반부에 위치시키고 이 영역에 대해서는 4MB단위로 페이징하기도 합니다.
하지만 OS코드의 경우에는 한번 로드되고 나면 일반 프로세스처럼 이리저리 재배치될 필요가 없으며
또 어떤 프로세스보다도 자주 액세스되며, OS를 설계할 때부터 코드 크기를 가능한 4GB에 맞추어 제작함으로써
충분히 커더란 크기의 페이징 하에서도 유리하게 동작할 수 있습니다.
하지만 일반적인 프로세스의 경우 크게 페이지를 잡아버리면 심각한 내부 단편화문제가 발생하게 됩니다.
즉, 한 프로세스마다 평균적으로 페이지 크기의 절반인 2MB정도의 공간을 낭비하는 셈.
또한 페이징이라는 기법을 도입하게 된 결정적 이유인 구역성이 4MB안에서도 적용되는가 하는 것도 문제.
연구 결과 현대의 프로그램에서는 4KB가 여러 면에서 적합하다고 판단해서 주로 사용.
결국 페이지 크기를 늘리는 것은 근본적인 해결책이 될 수 없고 일반적인 해결책으로는 페이지 테이블을 위한
또 다른 테이블을 구성하는 것.
즉, 페이지 테이블의 각 항목이 메모리 상에서의 프레임 번호를 나타내는 대신 또 다른 페이지 테이블을
가리키게 하는 이중 페이지 테이블을 구성하는 것.

기존에는 한 프로세스의 코드와 데이터를 페이지라는 구획으로 쪼개고, 메모리도 같은 크기의 프레임으로 쪼개
이 둘을 맵핑하기 위한 테이블로서 페이지 테이블을 마련했다면, 이번엔 이 페이지 테이블을 하나의 프로세스처럼
또 다시 일정한 크기의 구획으로 쪼개고 이 구획을 메모리상에 맵핑하는 것.
(페이지 테이블 크기가 4GB인데, 구획 크기를 1KB로 잡으면 페이지 테이블을 총 4096개의 구획으로 쪼갤 수 있다.)
가령 페이지 테이블을 위한 공간으로 총 1MB 크기의 메모리를 확보했다면, 이 1MB의 공간을 다시 1KB단위로 쪼갭니다.
그리고 각 프로세스의 페이지 테이블 역시 1KB단위로 쪼개어 이 쪼개진 구획을 1MB크기의 공간에 맵핑해 나가는 것.
CPU가 액세스한 논리주소
|...|페이지 오프셋|
  |
  V
|외부페이지 테이블의 인덱스|외부페이지 테이블의 오프셋|
            |                        |
			V                        └─────────┐
1KB	|0|                 .               |      |    |0|.| ┐1KB
1KB	|1|                 .               |      |    |0|.| ┘
1KB	|2|프로세스2의 페이지 테이블의 1번 구획|  ┌────>1┌ |1|.|
1KB	|3|프로세스1의 페이지 테이블의 1번 구획| ─┘   └──└  ...
1KB	|4|프로세스2의 페이지 테이블의 0번 구획|          프로세스1의 페이지 테이블
     ...
CPU가 생성해 낸 논리 주소 중 원래 페이지 번호로 사용되던 구간을 또다시 이중을 쪼개서 상부는 외부 페이지 테이블
이라고 하는 페이지 테이블을 위한 메모리의 구획번호를 나타냅니다.
테이블의 인덱스를 나타내고 하부 비트들은 이 구획 안에서 다시 오프셋 값을 나타냅니다.
외부 페이지 테이블의 각 구획은 프로세스와 상관없이 1KB단위로 쪼개진 페이지 테이블의 구획에 맵핑됩니다.
따라서 논리 주소가 나오면 선 페이지 테이블을 쪼개서 맵핑한 외부 페이지 테이블의 인덱스를 찾고
이 구획 안에서 다시 오프셋 값을 이용해 최종적으로 메모리 상의 페이지 인덱스를 찾는 것.
그리고 논리 주소의 페이지 오프셋 값과 합쳐져서 원하는 메모리 주소를 얻습니다.
이런 경우 모든 프로세스 페이지 테이블을 메모리에 보관하는 대신, 프로세스를 페이지 단위로 쪼개서 현재
사용되는 페이지만 메모리에 로드하는 것처럼, 구획으로 쪼개진 페이지 테이블 중 현재 액세스 중인 구획만
페이지 테이블 메모리에 맵핑하고 이를 위한 외부 페이지 테이블만 매모리 상에 유지하는 것.
구역성을 활용하고자 프로세스와 메모리 사이에 페이지 테이블을 구성했던 것을 페이지 테이블과 페이지 테이블 메모리
사이에 한 단계 더 적용한 것.
즉, 논리주소->페이지테이블->물리 주소였던 것이 논리 주소->외부 페이지 테이블->페이지 테이블 메모리
->물리 주소 같이 된다.
이러면 전체 페이지 테이블 크기에 상관없이 원하는 크기만큼 페이지 테이블 메모리를 마련해 사용할 수 있으므로
메모리를 훨씬 아낄 수 있습니다.
물론 페이지 테이블 전체를 메모리에 가지고 있는 경우보단 조금 느리지만 페이지 테이블 역시 공간 구역성이
적용되어 한번 로드된 구획은 한동안 계속 활용되어 메모리 절약 효과에 비해 퍼포먼스 손실은 없다.
실제 윈도우에서도 이런 개념을 그대로 적용해서 사용합니다.
단지 외부 페이지 테이블에 해당하는 것을 페이지 디렉토리(Page Directory)라고 부른다.
가상 메모리 방식에도 결정적인 단점이 있습니다.
페이지 테이블로 인한 메모리 액세스 횟수의 증가입니다.

06 페이지 테이블을 위한 캐쉬 메모리 - TLBs
패치하는 과정은 CPU는 인스트럭션을 읽어오기 위해 물리 메모리 주소와 상관없이 프로세스 기준으로 논리 주소를
생성할 것입니다(PC레지스터의 값이 논리 주소).
1단계 페이징 기법을 사용한다면 이 논리 주소는 우선 페이지 테이블의 인덱스로 활용.
페이지 테이블은 각 프로세스마다 생성되어야 하는데다가 하나로도 용량이 있어 일반적으로
프로세스 정보와 함께 메모리에 위치시키게 됩니다.
따라서 CPU로부터 논리 주소가 나오면 메모리 상에 위치한 페이지 테이블에서 메모리의 프레임번호를 읽어야 한다.
그리고 다시 이 프레임 번호가 논리 주소의 오프셋 값과 합쳐져서 다시 한번 메모리로부터 최종 인스트럭션을 가져옴.
만일 가상 메모리 기법이 사용되지 않고 CPU가 생성한 주소가 직접 물리 메모리의 주소라면 인스트럭션을
패치하기 위해 한번만 메모리를 액세스하면 되지만 가상 메모리 방식을 사용해 페이지 테이블을 통하는 경우
페이지 테이블을 액세스하기 위해 한 번, 실제 인스트럭션을 읽어오기 위해 한 번 해서 두 번 메모리를 액세스.
결과적으로 가상 메모리 방식을 사용하지 않을 때에 비교해 2배 가까운 메모리를 액세스해야하므로 성능에 지장.
이를 해결하기 위해 일반적으로 가상 메모리를 지원하는 CPU에는 독특한 하드웨어가 추가.
연관 레지스터(Translation Look - aside Buffers, TLBs)라 부르는 일종의 캐쉬 메모리.
캐쉬 메모리란 CPU 외부에 탑재하는 느린 DRAM과 달리 무척 속도가 빠른 SRAM이 CPU안에 내장.
캐쉬 메모리 역시 구역성에 근거해 패치하고자 하는 인스트럭션이나 데이터를 한꺼번에 큰 덩어리로 가져온다.
그러면 한동안 CPU는 외부 메모리로 액세스할 필요 없이 캐쉬 내부에서 해결할 수 있어 속도 향상.
이런 캐쉬메모리와 같은 것을 페이지 테이블을 위해 전담하게 된 것이 TLBs.
TLBs도 캐쉬메모리처럼 SRAM과 같은 빠른 메모리로 CPU 내부에 탑재.
그리고 메모리를 액세스할 때마다 페이지 테이블을 검색하기 전에 우선 TLBs를 살펴보게 된다.
TLBs는 2개의 항을 가진 테이블로 첫번째 항은 논리 주소의 페이지 번호, 두번째 항은 물리 메모리에서의 프레임 번호.
그리고 논리 주소가 생성되면 이 주소의 페이지 번호 비트들은 TLBs의 모든 행의 첫 번째 항과 동시에 비교합니다.
(이를 동시에 비교하기 위해서 하드웨어가 복잡해지고 비싸진다)
그리고 일치하는 행이 발견되면 그 행의 프레임 번호가 곧바로 활용되는 것.
즉, 페이지 테이블까지 갈 필요없이 TLBs만으로 물리 주소가 생성.
만일 일치하는 페이지 번호가 존재하지 않으면, 페이지테이블로가서 프레임 번호를 읽어옵니다.
그리고 TLBs의 한 행에 액세스한 페이지 번호와 프레임 번호를 기록해 둡니다.
그러면 구역성에 의해 한동안은 해당 페이지에 대한 액세스가 계속 일어나므로 한번 페이지 번호가 TLBs에 등록되면,
당분간은 페이지 테이블을 읽을 필요없이 TLBs만으로 물리 주소를 생성할 수 있습니다.
TLBs의 행 수가 적어도(2000개 내외) 이 효과는 대단합니다.
TLBs를 이용한 페이지 테이블 액세스 수 감소 -> 메모리 액세스 횟수 줄임 -> 속도 향상
CPU ------------> 논리주소 
TLBs의 모든 페이지 |페이지번호|오프셋|
번호항과 동시에 비교     |       └──────────────────────────────────────────────┐
↑					   |  페이지번호항 프레임번호항   일치항목 발견               ↓
|					   ├>|           |          | ──────────────>|프레임번호|오프셋| ─┐
|              일치항목 |            ...                           ↑                 |
|				미발견  |              ↑                           |                 |실제 메모리 주소
|				       |              |TLBs 중 한 행 업데이트       |                 |
|				       └────────페이지테이블────────────────────────┘                 |
|     				                         인스트럭션 또는 데이터 공급               |
└───────────────────────────────────────────────────────────────────────── 메모리 <───┘
CPU로부터 논리 주소가 나오면 이 논리 주소의 페이지 번호 비트들이 TLBs의 모든 페이지 번호 항과 동시에 비교됩니다.
그리고 이 중 일치하는 행이 있으면 그 행의 프레임 번호 항과 논리 주소의 오프셋 값이 합쳐져 물리 메모리 주소를
구하게 됩니다.
따라서 페이지 테이블을 액세스할 필요 없고 TLBs에 대한 액세스는 메모리 액세스와는 비교안되게 빨라 속도가 향상.
한편 TLBs에서 일치하는 항을 찾지 못하면 페이지 테이블로 가서 페이지 번호에 해당하는 인덱스를 찾아 프레임번호를 읽음.
그리고 이 프레임 번호와 논리 주소의 오프셋을 합쳐 물리 메모리 주소를 생성하는 것.
또한 TLBs에서 한 행을 선택해 그 행을 지금 액세스한 페이지 번호와 프레임 번호로 업데이트합니다.
(선택하는 방법도 여러가지있다. 차례대로 사용하거나 오래된 항을 서로 바꿀수도 있다)
따라서 다음에 이 페이지 번호에 해당하는 논리 주소가 나오면 TLBs에서 곧바로 찾을 수 있다.

07 페이징을 통한 프로세스간 메모리 공유
페이징을 사용하면 각 프로세스는 각자의 페이지 테이블을 통해 물리 메모리에 접근하게 되므로 페이지 테이블만 
잘 조작하면 서로 다른 프로세스가 같은 주소의 물리 메모리를 액세스할 수 있습니다.
만일 익스플로러가 코드 부분과 데이터 부분으로 명확히 나누어져 있다면 모든 익스플로러 프로세스에서
코드 부분을 따로 메모리로 로드할 필요가 없습니다.
코드 부분은 동일하고 서핑하는 내용에 따라 데이터만 달라지니까.
코드 부분은 실제 메모리상에 한 번만 로드하고, 데이터에 한해서만 각 프로세스 별로 로드할 수 있다.
그리고 각 프로세스의 페이지 테이블에서는 코드 부분을 가리키는 주소는 공통적을 사용하고,
데이터 부분만 각자의 데이터를 가리키도록 구성하면 되는 것.
모든 프로세스가 공용으로 사용하는 코드를 한번만 메모리에 로드하고, 모든 프로세스가 페이지 테이블을 잘
조작하여 이 공용 코드가 로드된 주소를 가리키도록 하여 메모리를 절약할 수도 있다.
실제로 윈도우즈에서는 동적 연결 라이브러리(Dynamic Linking Library, DLL)이 이 기술을 활용.

윈도우즈에서는 4GB의 프로세스 공간 중 상위 2GB는 항상 DLL을 위한 공간으로 활용.
그리고 WIN32 API로 불리는 윈도우즈가 제공하는 시스템 함수들은 모두 DLL 형태로 구성되어 있다.
사실상 윈도우즈에서 돌아가는 응용프로그램들은 코드의 상당부분이 API호출로 이루어져 있으므로
이런 API들을 DLL로 구성하는 것만으로도 윈도우즈는 상당한 양의 메모리를 절약하는 셈.
API함수들이 DLL형태가 아닌 일반 라이브러리 같은 정적인 형태로 컴파일하면서 결합된다면 메모리 사에는
수많은 중복된 API코드들이 산재할 것입니다.
DLL이라 할지라도 코드 부분만 공유된다는 것이지 CreateWindow라는 API함수로 창을 하나 생성하면
그 안에 들어가는 여러 파라미터라든지 내부 변수들은 각 프로세스마다 다를 것.
따라서 이런 데이터 부분은 메모리 상에서 공유되면 안되고 API함수가 호출될 때마다 서로 다른 메모리를 차지하고
있어야 하는데, 이는 스택이라는 구조를 통해 자연스럽게 해결됩니다.
스택은 각 스레드마다 하나씩 보유하게 되는 고유의 영역.
결국 프로세스보다 작은 단위인 스레드마다 스택을 보유하고 이 스택안에 DLL함수를 포함한 모든 함수의
변수들이 생성되므로, 결과적으로 각 DLL함수라 할지라도 코드만 공유될 뿐 데이터 자체를 호출될 떄마다
다른 메모리상에 생성되는 것.
함수 이름의 괄호를 제거하면 그 자체가 포인터가 되므로 그 주소를 통해 데이터처럼 액세스도 가능한데,
만일 악의를 품고 DLL함수 코드 부분을 수정할 수도 있을 것이다.
그러면 바이러스를 파일마다 전파시키는 방법이 될수도 있었을 것이다.
실제로 도스에서는 비슷한 방법을 활용해 바이러스를 만들었다.
API대신 도스 시절엔 소프트 인터럽트라는 것을 통해 이런 방식의 파일 입출력을 했는데,
인터럽트를 호출하는 매커니즘이 미리 정해진 메모리 상에 인터럽트 벡터라는 것이 있어 인터럽트가 호출되면
이 벡터 값이 가리키는 주소로 점프하는 방식.
따라서 이 벡터 값을 원래의주소가 아니라 임의로 만든 코드 주소로 바꿔놓고 그 코드가 어떻게든
종료되지 않게 하면 이후 실행되는 프로그램들이 파일을 열기 위해 해당 인터럽트 루틴을 호출할 때마다 파일
오픈 루틴이 아니라 임의로 지정해 둔 루틴이 호출되는 것.
(도스 시절엔 램상주(TSR)라는 형태로 가능했다.)
그리고 그 코드는 몰래 오픈했던 파일에 바이러스 코드를 첨부해서 원래 파일 오픈 루틴으로 점프하는 것.
그러면 프로그램은 결과적으로 파일 오픈 루틴을 호출한 셈이 되고, 순식간에 바이러스가 퍼지는 것.
이런식으로 API루틴을 가로채는 것은 API훅킹이라고하는데, 지금 OS에서는 단순히 API함수 주소에 직접
코드를 써 넣는 방식으로는 불가능합니다.
지금의 CPU에서는 세그먼테이션이라는 것을 통해 용도에 따라 메모리를 보호할 수 있기 때문.
즉, 코드 부분에 해당하는 메모리 영역은 쓰기는 불가능하고 읽기만 가능하게 하는 식으로 적절한 보호기능.
80x86시절부터 세그먼테이션을 사용해왔습니다.
386 PC가 등장할 무렵부터 점점 커진 메모리와 멀티 프로그램을 지원하는 윈도우즈 같은 OS의 등작으로
페이징 기법을 도입해 병행 사용하게 된 것.

08 CPU의 시간표 - 스케쥴링
프로세스 개수보다 적은 CPU로 어떻게 여러 개의 프로세스를 공평하게 수행하느냐.
프로세스에게 눈속임을 제공하기까지는 OS의 부단한 노력이 있어야 합니다. (CPU도)
윈도우즈와 같은 멀티 프로그램 OS의 결정적인 역할이 바로 모든 프로세스가 논리적으로 끊임 없이 실행될 수 있도록
CPU의 수행권을 공평하게 분배해주는 스케쥴링(Scheduling)입니다.
결국 스케줄링이라는 것은 프로세스의 수행을 잠시 멈춰두고 다른 프로세스를 수행하는 방법.
OS의 가장 큰 책임 중 하나는 프로세스가 문맥 전환을 당할 때 알아채지 못하게 눈속임 해주는 것.
그리고 유일한 방법이 현재 수행중이던 프로세스에 관련된 정보를 어딘가에 저장해두고 다음 번에 수행을 재개할 때
이 정보를 원래 상태 그대로 복구해주는 방식.
노트북의 최대 절전 모드를 사용하면, 모든 메모리의 내용과 CPU레지스터 값 등을 몽땅 하드디스크에 백업합니다.
그리고 전원을 꺼버립니다.
이후 다시 전원을 키게 되면 윈도우즈가 부팅을 하다 말고 백업 데이터가 있는 것을 발견하고 정상적인 부팅 절차를
거치지 않고 메모리와 CPU를 백업 데이터로 싹 옮겨버립니다.
그래서 노트북은 전원을 끄기 전과 똑같은 상태로 돌아가는 것.
프로세스의 가장 기본이 되는 정보가 CPU의 현재 수행 상태입니다.
수행 상태라는 것은 현재 메모리의 어느 주소를 패치해서 인스트럭션을 수행 중이었고, 이전 인스트럭션들의
수행 결과 레지스터의 값이 어떻게 되어 있는가 하는 정보입니다.
즉, 레지스터의 값이 그 시점에서의 CPU의 수행 상태인 것.
따라서 문맥 전환에서 가장 중요한 것이 모든 레지스터의 값을 백업받는 것.
백업은 일반적으로 프로세스마다 할당되는 PCB(Process Control Block)라는 구조체에 하게 됩니다.
윈도우즈에서는 프로세스에서 스레드라는 개념을 독립시켜서 한 프로세스가 여러 스레드를 가질 수 있게 하다보니
TCB(Thread Control Block)에 레지스터를 백업합니다.
이 외에도 프로세스의 중요한 정보 중 하나가 바로 메모리입니다.
그 중에서도 현재 수행되던 코드와 데이터가 저장되어 있는 메모리가 필수적.
이를 위한 해결책이 페이징 같은 기법이었습니다.
즉, 각 프로세스마다 페이지 테이블을 유지하고 CPU가 수행을 하면서 논리 주소가 생성이 될 때마다 
이 페이지 테이블을 참조해서 프로세스의 코드나 데이터를 메모리로 옮겨오는 방식.
따라서 프로세스가 문맥 전환이 될 때 메모리와 관련해서 저장해야 할 가장 중요한 정보가 바로 페이지 테이블.
이 외에도 프로세스마다 할당되는 여러 핸들 값이나 프로세스 이름 등 정보들이 모두 PCB에 저장됩니다.
사실 CPU입장에서 놓고보면 프로세스나 OS 같은 것을 알 수 없습니다.
그저 기계적으로 정해진 룰에 따라 PC레지스터가 가리키는 주소의 인스트럭션을 패치해서 수행하는 것이기 때문.
즉, 현재 수행되는 프로세스의 코드가 어느 프로세스인지 OS의 코드인지 알 수가 없는 것.
그러면 OS는 언제 어떻게 현재 수행 중인 프로세스를 멈추고 다른 프로세스가 수행될 수 있도록 문맥전환할까?
비선점형OS에서 문맥 전환을 해주는 결정적 타이밍은 프로세스가 호출하는 시스템 콜(API함수호출)이었습니다.
사실 한번 프로세스가 CPU에 의해 수행되기 시작하면 아무리 OS라해도 중간에 끼어들 수가 없습니다(인터럽트말고)
결국 OS의 코드가 수행될 수 있는 기회는 OS가 제공하는 API함수를 프로세스가 자발적으로 불러주는 경우.
그리고 이 API함수에서는 함수 수행 후 곧바로 호출한 프로세스의 코드로 리턴하는 대신 문맥 전환하려는
OS 내부 함수를 호출합니다.
즉, 현재 대기 중인 다른 프로세스의 정보를 다시 복구하여 CPU가 새로운 프로세스의 코드를 수행하도록 하는 것.
API함수를 호출했던 프로세스는 다시 OS가 기회가 생겨 자신의 정보를 복구한 후 수행시켜주기 전까지는
자신이 멈춰 있다는 사실조차 모른 채 있는 것.
그리고 수행이 정지되었던 프로세스가 수행을 재개하면 이 프로세스는 아무일도 없었던 것처럼 호출한 API함수로부터
리턴되고 하던 일을 계속할 수 있습니다.
즉, OS가 문맥 전환 때마다 해당 프로세스의 모든 정보를 정지 이전의 상태로 돌려 놓음으로써 논리적인
흐름의 끊김 없이 수행할 수 있게 해주는 것.

프로세스A        OS함수(API) Sleep함수 내부             OS함수(API) Read파일 함수 내부
|...      |  1.  |...              |                  |...              |
|Sleep(10)| ---> |...              |         5.       |...              | <┐              
|...      |      |문맥 전환 함수 호출|    ┌────────────|문맥 전환 함수 호출|  |
    ↑                    ↓2.             |                                 |4.
	|	6.	       문맥 전환 함수   <─────┘    3.       프로세스B            |
	└──────── 다음 차례의 프로세스 스케쥴링  ---------> |...         |		   |										              
프로세스A선택		                         프로세스B선택 |Read파일(..)|───────┘
프로세스A가 CPU에 의해 수행이 되다가 Sleep이라는 OS함수(API함수)를 호출하였습니다.
이 Sleep함수는 프로세스A에 의해 호출되긴 했지만 프로세스A의 코드가 아니라 OS가 제공한 코드입니다.
따라서 이 코드 안에서는 다른 프로세스를 스케쥴링할 수 있도록 문맥 전환 함수를 호출합니다.
그리고 이 문맥 전환함수는 정해진 알고리즘에 의해 다음으로 실행하게 할 프로세스를 결정합니다.
선택된 것이 프로세스B라면 프로세스B의 PCB를 참조해 각종 문맥 전환을 위한 복구를 합니다.
예로 프로세스B가 이전에 수행을 멈춘 시점에 백업받은 레지스터 값을 복구하거나 하는 일들.
그리고는 이전 프로세스B가 수행하던 위치로 점프하면(PC레지스터를 그 주소로 셋팅) 프로세스B는 이전에
수행을 정지했던 시점에서 논리적 단절없이 수행할 수 있다.
프로세스B의 코드가 다른 OS함수인 ReadFile을 호출하게 되는데 ReadFile안에서는 또 다시 문맥전환 함수를 호출하고
이 문맥 전환함수는 다음 순위의 프로세스를 선택하며 다시 프로세스A가 선택됨.
이런 비선점OS에서는 단점이 있는데 프로세스에 의한 기아(Starvation)상태.
비선점 OS가 문맥 전환을 시킬 수 있는 기회를 얻는 가장 주된 방법이 프로세스의 자발적인 OS함수호출이었습니다.
그런데 의도적이던 아니던 만일 한 프로세스가 긴 시간 동안 API함수를 호출하지 않는다면 어떻게 될까?
OS는 다른 프로세스에게 문맥 전환을 해 줄 기회를 얻지못하고 결과적으로는 다른 모든 프로그램들은
정지 상태로 있어야 합니다. 시스템이 먹통이 되는 것.
윈도우즈 95에서는 이 때문에 재부팅해야 하는 경우가 많았습니다.
그래서 이후에 개선해서 나온것이 선점형(Preemptive)스케쥴링을 지원하는 윈도우즈 98이었습니다.
이전의 비선점형 OS에서는 프로세스의 자발성이 포인트였는데, 프로세스를 각기 다른 응용 프로그램 개발자들이
만들다 보니, 제때 API함수를 호출하는 구조로 만들기 어려운 경우가 있었다.
선점형 방식이란 응용 프로그램들이 API함수를 제 때 호출해주지 않더라도 인터럽트를 통해 주기적으로
문맥 전환을 해주는 것.
사실 선점형 OS에서도 여전히 API함수의 호출이 결정적인 문맥 전환의 기회로 활용되고 있습니다.
하지만 선점형 OS에서는 타이머 인터럽트라는 것을 더해 API함수가 호출이 되든 아니든 주기적으로 OS코드가 수행.
인터럽트는 외부 신호에 의해 CPU가 잠시 하던 일을 멈추고 정해진 루틴으로 점프하는 것.
외부신호라는 것은 키보드 입력이나 패킷 전달 등 여러 I/O장치로부터의 입력.
성능이 좋지 않았던 예전의 CPU에서는 인터럽트 없이 CPU가 항상 I/O장치를 주기적으로 살피는 풀링(Pooling)방식.
일단 인터럽트가 걸리면 CPU는 현재 수행하던 인스트럭션까지만 수행하고 그 다음 인스트럭션을 패치해 와서
수행하는 대신, 인터럽트 종류에 따라 정해진 주소로 점프하게 됩니다.
그리고 그곳에는 해당 인터럽트에 대한 처리를 하는 코드(인터럽트 핸들러)가 존재합니다.
이후 코드의 수행이 끝나게 되면 다시 원래 수행하던 지점으로 되돌아가 하던 수행을 계속합니다.
인터럽트 핸들러는 인터럽트 종류에 따라 각자 하는 일이 다릅니다.
키보드입력에 대한 인터럽트 핸들러에서는 키보드 버퍼에 있는 데이터를 읽어와 OS가 처리할 수 있게 한다든지,
랜 카드에서 발생한 패킷 도착 인터럽트 핸들러는 도착한 패킷을 네트워크 처리를 담당하는 상위 레벨
프로토콜로 전달해서 적절한 행동을 취할 수 있게 합니다.
대표적인 것 중 하나인 타이머 인터럽트는 정해진 시간이 경과하면 시그널을 발생시키는 외부의 타이머
레지스터에 의해 발생하게 됩니다.
시스템에는 여러가지 타이머 인터럽트의 소스들이 있는데 그 중 하나가 OS의 스케줄링에 활용되는 것.
선점형 OS는 프로세스가 OS함수를 호출해 줄 때까지 수동적으로 기다리기만 하는 대신 타이머를 설정해서
주기적으로 인터럽트가 걸리도록 합니다.
그리고 그 인터럽트의 핸들러로 바로 스케줄링 코드, 문맥전환을 해주는 코드를 준비해 두는 것.
그러면 특정 프로세스가 독점하더라도 타이머 인터럽트에 의해 주기적으로 문맥전환 코드가 수행될 것이고,
결국 프로세스들은 기아현상 없이 균등하게 수행될 수 있습니다.

결국 OS는 그자디 능동적으로 작동하지는 않습니다.
그나마 선점형 OS에서는 타이머 인터럽트를 통해 주기적으로 실행이 되긴 하지만 비선점형 OS에서는 OS코드가
수행될 수 있는 기회가 프로세스의 자발적인 OS함수 호출이나 I/O장치들의 인터럽트 발생에 의해 실행되는
디바이스 드라이버의 코드 정도.
OS는 일종의 라이브러리 같은 형태로, OS함수(API함수)를 제공하고 이 API함수를 호출하도록 작성된 프로그램에
의해 전체적인 시스템 운영을 해나가지 보조적인 역할을 할 뿐입니다.
메모리 관리 역시 프로세스가 자발적으로 동적인 메모리 할당을 위해 메모리 할당용 OS함수(HeapAlloc 등)을
호출할 때 비로소 해당 함수 안에서 일어나는 것.

09 실시간 운영체제
직접 운영체제 커널을 제작하고 OS가 다루는 각종 알고리즘에 대해 모두 파악하고 실무에 활용할 일은 드물다.
대신 OS를 어느정도 이해함으로써 그 위에서 돌아가는 응용 프로그램을 개발할 때, 견실하게 작성할 수 있다.
RTOS(Real Time Operating System)에 대한 오해는 바로 실시간 운영체제를 사용하면 매우 빨리 프로세스가 수행되고
그 위에서 돌아가는 프로세스가 어떻게 구성되는가와 상관없이 어떤 경우에도 OS가 실시간성을 보장해준다고 생각하는 것.

실시간 시스템이란
1)프로세스가 수행한 작업 결과의 내용뿐 아니라 이 작업 결과가 도출되는 시점이 중요한 목표가 되는 시스템
2)외부에서 임의로 발생하는 데이터를 항상 예측 간으한 시간 안에 처리할 수 있도록 준비된 시스템
3)시간적 제약이 있는 작업을 다루는 시스템
이미지 뷰어는 JPEG파일을 읽어 이를 디코딩해서 화면에 그리기까지 시간이 큰 문제가 되지 않는다.
하지만 초당 30프레임의 MPEG2로 인코딩된 DVD영상을 재생하는 프로그램이 한 프레임을 디코딩하는데 1초가 걸린다면
문제가 된다. 이런 제약이 있는 시스템에 실시간 시스템.

실시간 시스템은 실패했을 때 초래하는 결과에 따라 Hard Read Time System, Soft Real Time System 등으로 나뉨.
심장 보조 장치 같은 시스템 같은 결과가 비극적인(Catastrophe)인 경우 Hard Real Time System.
DVD Player처럼 짜증은 나지만 불가능한 것은 아니므로 Soft Real Time System.

키보드를 누를 때마다 화면에 글자를 출력하는 프로그램을 만들 때 실시간성이란 키보드가 눌리면 주어진 시간안에
화면에 글자가 출력되는 것.
반응 속도가 가장 큰 이슈.
실시간성이란 이런 반응 속도를 우리가 원하는 범위 안에 들게 하는 것인데, 평균적인 반응 속도가 빠른 것이 중요한
것이 아니라, 평균속도는 느리더라도 반응속도가 일정하거나 적어도 정해진 최대 반응 시간 이내에 무조건 실행되는 것.
'예측'가능한 반응 시간이 실시간성에 있어서 가장 중요한 부분인데, 일단 반응 시간에 대해서 예측만 가능하다면
속도가 모자라는 부분에 대해서는 더 빠른 하드웨어를 사용하거나 더 빠른 알고리즘을 사용하면 된다.
만약 OS없이 직접 코드를 작성하고 시스템을 최소화하여 키보드에 반응하는 루틴만 작성했다면 실시간 시스템으로
인정받는데 어려움이 없을 것입니다.
왜냐하면 일단 시스템이 완성되고 실행되면 키보드에 반응해 화면에 글자를 출력하는 루틴 외에 특별히 다른 입력이나
생각지 못했던 일이 벌어지는 경우가 없기 때문에 항상 일정한 반응 시간이 나올 것이기 때문.

시스템의 가장 전형적인 처리과정을 살펴보면 크게 두가지인데 첫번째는 폴링(Polling)방식
1)프로그램이 무한 루프를 돌면서 키보드 버퍼를 확인한다.
2)버퍼에 어떤 값이 들어오게 되면 그 값을 읽어 비디오 화면에 출력한다.
두번째는 인터럽트(Interrupt)방식입니다.
1)프로그램은 아무 것도 하지 않은 채로 계속 무한 루프를 돌고 있다.
2)키보드가 눌리면 인터럽트가 발생하고 프로그램은 자동적으로 즉시 미리 지정된 인터럽트 처리 루틴으로 점프.
3)인터럽트 처리 루틴 안에서 화면에 글자를 출력한다.
즉, 하드웨어적으로 CPU의 특정한 포트에 시그널이 들어오면 CPU가 곧바로 지정된 주소로 점프하여 루틴을 실행.
가장 큰 차이는 어떠한 외부 입력을 기다리는 동안 CPU가 다른 일을 할 수 있는가 없는가의 차이.
폴링 방식의 경우 가장 직관적이고 단순하게 프로그램을 만들 수 있는 장점이 있지만 CPU가 항상 해당 I/O를
주기적으로 체크해야 하므로 다른 일을 하기 힘들다.
인터럽트방식에서는 I/O이벤트가 발생하기 전까지 CPU는 다른 일을 할 수 있다는 장점.
인터럽트 방식의 효용성 때문에 지금은 거의 대부분 시스템에서 인터럽트를 기본 방식으로 채용.

이렇게 인터럽트 방식을 사용해 키보드 입력 시스템을 만들었다고 가정합시다.
CPU는 그저 무한 루프를 돌 뿐이고 언제라도 인터럽트가 걸리면 키보드 처리 루틴으로 점프하여 화면에 글자를
출력하므로 전혀 지체됨 없이 완벽한 실시간 시스템을 만들 수 있을 것이다.
그런데 마우스 입력까지 받을 수 있도록 시스템을 개조해보자.
마우스 입력에 대해서도 처리를 할 수 있도록 키보드와 별도의 다른 인터럽트 라인이 있어야 합니다.
그리고 마우스의 움직임이 있을 때마다 인터럽트를 발생시킬 것입니다.
즉, 마우스의 X,Y좌표에 대한 변이값(offset)이 CPU로 전달되고, 인터럽트가 CPU에 알려지면 CPU는 하던 일을
멈추고 해당 인터럽트 처리 루틴으로 가서 마우스의 변이 값을 읽어올 것입니다.
그리고 화면에는 마우스 커서가 표시됩니다.
그럼 여전히 이 시스템은 실시간 시스템일까요?

인터럽트가 발생하면, CPU는 인터럽트 벡터라는 것을 검토하게 됩니다.
결국 메모리의 데이터 값으로, OS나 사용자 프로그램 같은 곳에서 미리 지정한 주소값이 됩니다.
그러면 CPU는 인터럽트 소스에 따라 해당 인터럽트 벡터의 값을 메모리에서 읽어 그 주소로 점프합니다.
그리고 그 주소에는 해당 인터럽트에 대한 처리를 할 수 있는 코드가 있습니다.
주의할 점은 이런 인터럽트는 아무 때라도 발생할 수 있습니다.
즉, 사용자가 언제 키보드를 누를지 알 수 없으므로 인터럽트가 발생해서 해당 처리 루틴으로 점프하게 되는
시점이 CPU가 어느 코드를 처리하는 중이었는지 예측할 수 없는 것.
따라서 인터럽트 처리 루틴은 항상 이 부분에 대해서 처리할 수 있도록 작성되어야 합니다.
대표적이고 기본적인 방법이 해당 인터럽트 처리 루틴 안에서 사용하는 모든 레지스터 값을 백업해 두는 것.
다만 백업할 수 없는 한가지가 PC레지스터의 값입니다.
이는 현재 수행중인 코드의 주소이므로 인터럽트 처리 루틴이 실행 중이란 얘기는 이미 PC레지스터의 값이
원래 수행중이던 코드의 주소가 아닌 인터럽트 처리 루틴을 가리키고 있다는 얘기.
따라서 이 부분에 대한 책임은 소프트웨어가 아닌 CPU스스로 책임을 지게 되는데, 인터럽트가 걸리게 되면
하드웨어적으로 그 시점의 PC레지스터값을 백업하게 됩니다.
그리고 인터럽트 처리 루틴에서는 할일이 다 끝나고 자동으로 백업해 둔 PC주소값으로 다시 점프해서 원래
수행 중이던 코드를 계속 수행하게 되는 것.
그리고 이 때 가장 중요한 것이 인터럽트 처리 루틴 안에서 사용했던 레지스터 값들을 다시 원상 복귀 시킴으로서
원래 수행 중이던 코드가 이상없이 작동해야 한다.

만일 인터럽트 처리 루틴이 수행 중일 때 다시 인터럽트가 발생한다면?
인터럽트가 걸려 있는 동안에는 다음 인터럽트가 발생할 수 없습니다.
인터럽트가 발생하게 되면 기존에 수행 중이던 코드로 복귀하기 위해 PC레지스터를 필수적으로 백업해야 하는데,
이 작업이 소프트웨어가 아닌 하드웨어에서 처리되기 때문.
만일 소프트웨어적으로 처리된다면 스택 구조 등을 유지하면서 백업하면 되지만 하드웨어적으로는 처리가 힘들다.
따라서 일반적으로는 인터럽트가 걸리면, 제일 먼저 진행되는 일이 PC레지스터에 대한 백업과 함께 다른
인터럽트가 걸리지 못하도록 하는 일.
이런 작업은 자동으로 이루어지는데, 인터럽트와 관련된 특정 레지스터의 'Interrupt Enable Bit' 등을 0으로
셋팅해서 인터럽트가 발생하더라도 무시하도록 만드는 것.

하지만 이런 경우는 여전히 실시간 시스템이라고 얘기할 수 있습니다.
왜냐하면 얼마간격인지 알려줄 수 있고, 더 빠른 CPU를 쓰거나 인터럽트 처리 루틴을 더 효율적으로 작성해
더 빠르게 처리할 수 있게 하면 되니까.
그런데 마우스 입력까지 고려된 시스템의 경우는 다릅니다.
장치가 하나인 경우는 최소 시간 간격을 측정해 하드웨어나 소프트웨어 자체의 개선으로 원하는 실시간성을
이룰 수 있습니다.
하지만 입력 소스 자체가 두 개 이상으로 다원화되는 경우, 최소 시간 간격이라는 개념이 불가능합니다.
따라서 마우스가 움직여 인터럽트가 걸리고, 키보드는 작동하지 않을 것입니다.
마우스 인터럽트의 처리 루틴 동안 키보드 인터럽트가 나중에 실행될 수 있다 하더라도 여전히 문제.
수행 시간에 대한 보장을 할 수 없어 더 이상 실시간 시스템이라고 부를 수 없는 것.
일반적인 경우 사용되는 인터럽트 소스는 훨씬 많고, 그 용도 역시 미리 정해져 있지 않은 경우가 대부분.
PC의 경우 IRQ라고 해서 미리 정해져 있지 않은 인터럽트 라인으로 슬롯 등을 통해 어떤 장치가
연결되는가에 따라 할당되는 IRQ번호가 달라집니다.
그래서 장치의 사용 용도에 대한 제약을 둠으로써 해결하는 방식은 불가능.

또다른 형태의 해결 방안이 필요한데 미션을 맡는 것이 OS입니다.
실시간 시스템을 만들기 위해서는 실시간 인터럽트 처리를 지원할 수 있는 OS가 있어야 합니다.
그리고 이런 OS를 우리는 실시간 OS, RTOS라고 부르는 것.
RTOS는 언제라도 발생할 수 있는 수 많은 인터럽트에 대해, 일정한 시간에 그 처리를 끝낼 수 있게 해줌으로써
한 인터럽트의 처리로 인해 다른 인터럽트가 걸리지 못하는 상황을 최대한 줄여줍니다.
이 방법은 인터럽트 핸들링 루틴을 두 단계로 나누어 놓은 것.
RTOS의 인터럽트 처리 루틴에서는 실질적으로 해당 인터럽트에 대한 처리를 하지 않습니다.
대신 해야 할 일에 대한 목록을 작성하고, 필요하다면 해당 목록의 버퍼에다가 필요한 데이터를 저장하여
이 일을 뒤로 미룹니다.
그리고는 인터럽트 처리 루틴에서는 곧바로 리턴합니다.
그리고 이 처리 루틴은 나중에 시스템이 여유가 있을 때 비로소 실행되는 것.
이렇게 되면 결과적으로 인터럽트 처리에 대한 속도 자체는 뒤로 밀려 더 느려질 수도 있지만,
적어도 인터럽트 처리 루틴 자체는 실제 해야 할 일에 대한 스케쥴링만 하고 리턴하므로 매우 빨라집니다.
즉, 해야할 일에 상관없이 공통적인 처리 루틴이 될 수있고, 속도 또한 매우 빨라 다른 인터럽트가 발생할 수 없는
기간이 짧아지는 것.
인터럽트는 RTOS가 아니더라도 많은 OS에서 이런 방식으로 인터럽트에 대한 처리를 다원화하고 있습니다.
리눅스도 RTOS는 아니지만 이런 방식으로 처리를 하는데 Bottom Half나 SoftIRQ라고 부르는 것들이 이중 처리 방식.

다단계 인터럽트 처리만 지원하면 무조건 RTOS일까?
인터럽트 처리 루틴을 다단계화하여 실질적인 처리 루틴은 나중에 여유 있을 때 실행되도록 스케줄링하는데,
또 다른 필수 요건이 담겨있습니다.
우선순위가 있는 처리 방식입니다.
한 프로세스가 일정 시간 수행되고 다른 프로세스 코드가 수행되어야 하는데, 다음 프로세스를 정하는 기준이 무엇인가.
가장 쉬운건 순서대로 한 번씩 돌아가는 방식.
하지만 여러 프로세스 사이에서도 우선순위라는 것이 있습니다.
예를 들어 윈도우즈에서 시스템에 오류가 있어 버벅여도 작업관리자는 대체로 재빠르게 나옵니다.
이는 작업관리자 프로세스가 다른 프로세스보다 우선순위가 높게 설정되어 있어 스케줄링 경쟁에서 항상 우위.
실질적인 인터럽트 처리 루틴을 뒤로 미루는 것이 OS입장에서 간단한 것이 아닙니다.
각 인터럽트 종류별로, 뒤로 미룬다는 개념을 구현하려면 우선 순위가 높은 작업을 여러 가지로 분리할 수 있는
매커니즘인 프로세스의 개념이 있어야 하고, 후에 여유 있을 때 작업을 수행한다라는 개념을 구현하려면,
이런 프로세스의 경쟁 상태를 나타내느 우선순위라는 개념이 있어야 합니다.
여유 있을 때 수행할 작업들은 우선 순위가 낮게 설정해두면 다른 프로세스들이 다 수행되고 CPU가 한가해질 때
비로소 그 작업이 수행되는 것.
이런 우선순위 개념이 도입되고 나면 RTOS가 필수적으로 선점성을 지원해야 합니다.
우선 순위가 있다는 것은 수행되기를 기다리는 여러 프로세스 중 우선 순위가 높은 순으로 스케줄링하는건데,
OS가 선점형이 아니면 우선순위가 역전되는 현상(Priority Inversion)이 발생.
즉, 비선점형 OS에서는 우선순위 프로세스가 수행시켜달라고 대기해도 우선순위가 낮은 프로세스가 자발적으로
CPU를 놓아주지 않는 이상 다른 프로세스가 수행될 수 없는 것.
따라서 RTOS가 지녀야할 특징은
1)선점형(Preemptive) 방식
2)우선순위 스케줄링 지원
3)인터럽트 지연(Interrupt Latency). 즉 인터럽트가 걸리지 못하는 시간이 일정해야 함.
그리고 동시에 각 조건을 만족해야 합니다.

여기 한가지 더 추가해보자면 스케줄링 지연시간(Scheduling latency)가 일정해야 한다는 점.
스케줄러가 우선 순위와 상관없이 모든 프로세스에 대해 단순히 순서대로 실행하도록 스케쥴링을 한다면
다음 순서의 프로세스를 찾는데 걸리는 시간은 일정할 것입니다.
하지만 우선 순위 스케쥴링을 지원하는 경우 스케줄링 시점이 되어서 다음 프로세스를 선택할 때 모든 프로세스를
검색해서 가장 우선 순위가 높은 것을 선택해야 할 것입니다.
문제는 '검색'하는 과정이 프로세스 수가 늘어날수록 길어질 수밖에 없다.
단순히 루프를 돌려가며 모든 프로세스의 우선 순위를 검사하면 프로세스 수에 비례해 탐색 시간도 증가.
RTOS는 '예측'가능한 동작이어야 하고 인터럽트 지연 시간도 일정하게 만들어야 합니다.
스케줄링 역시 가장 빈번하게 일어나는 작업인데 시간이 일정하지 않으면 RTOS 기본 요건을 불만족하는 것.
가장 중요한 컨셉은 '모든 동작이 예측 가능한 시간 안에 이루어져야 한다'.
RTOS는 일정한(Bounded) 인터럽트 지연(Interrupt Latency)와 스케줄링 지연(Scheduling Latency)을 구현하기 위해
평균적인 성능(속도)면에서는 다른 OS에 비해 떨어질 수밖에 없다.
그럼에도 RTOS가 필요한 이유는 주로 임베디드 시스템 같은 제어(Control)를 목적으로 하는 시스템의 경우
외부 입력으로부터의 반응과 데이터에 대한 처리 시간이 항상 예측 가능한 범위 안에 있어야 설계 지점부터
이에 맞추어 하드웨어를 구성하고 실제 동작에 있어서도 원하는 결과를 얻을 수 있기 때문.
예측 가능하기만 하면 모자란 성능 부분은 하드웨어나 알고리즘으로 해결 가능.
RTOS역할은 어디까지나 외부 입력인 인터럽트에 대한 반응 시간을 일정한 범위 안에 있게 해주고,
스케쥴러가 나름의 알고리즘을 통해 프로세스 수에 관계없이 항상 균일한 시간 간격으로 프로세스 스케쥴링을 하는 것.
프로세스가 많아지면 한 프로세스가 차지할 수 있는 시간(퀀텀)이 줄어들 수밖에 없고,
이 시간에 맞추어 충분히 원하는 데이터 처리를 할 수 있게 프로그램을 만드는 것은 순수하게 개발자의 몫.

리눅스와 윈도우즈는 실시간 운영체제는 아니다.
RTOS의 필수 요건인 선점성과 우선 순위 스케쥴링을 지원하는 OS입니다.
그리고 인터럽트 스레드나 SoftIRQ 등의 이름으로 인터럽트 처리에 있어서도 다단계화를 구현하고 있습니다.
즉, 어느 정도 제한된 시간 안에 인터럽트 지연이 생기도록 하고 있습니다.
가장 중요한 문제는 OS의 시스템 함수(커널 코드)가 선점성을 지원하지 못한다는 점.
응용 프로그램들이 자신의 코드를 수행하고 있는 동안은 자신보다 우선 순위가 높은 프로세스가 대기하는 경우
곧바로 우선 순위가 높은 프로세스에 의해 선점이 일어나게 되어 우선 순위에 맞게 프로세스가 수행될 순 있지만,
만일 낮은 우선 순위의 프로세스가 OS의 시스템함수(운영체제 API함수)를 호출한다면 이 시스템 함수는
운영체제의 코드(커널모드)로 선점성을 지원하지 않으므로 이 함수가 리턴하기 전까지는 다른 높은 우선 순위의
프로세스가 발생한다 하더라도 그 프로세스가 실행되지 않습니다.
따라서 완벽한 선점성을 지원하지 못하기 때문에 RTOS로 인정받지 못하는 것.

왜 커널 코드에서는 선점성을 지원하지 않는 것일까?
선점이 이루어지게 되면 난감한 상황이 발생하게 된다.
예로 A라는 프로세스가 CreateFile이라는 윈도우즈의 시스템 함수를 호출하여 파일을 생성했다고 합시다.
그런데 B라는 프로세스가 A보다 우선수위가 높아져 A가 CreateFile을 호출하는 도중에 갑자기 B로 문맥전환.
그런데 만일 B에서 A가 막 생성하고 있는 파일을 삭제하게 되면 나중에 A로 문맥전환이 될 때 문제가 발생.
즉, 파일의 핸들 값 등에 대한 관리는 운영체제 레벨에서 일관성 있게 이루어져야 하는데,
이런 경우 중간에 핸들이 뒤섞인다든지 하는 문제가 발생할 수 있다.
물론 세마포어 등의 동기화 객체를 사용해서 이런 자원을 모두 보호해주도록 하면 운영체제 코드인 커널도
선점성을 지원할 수 있지만, 굳이 범용 OS인 윈도우즈 등에서 그런 부담을 안아가면서까지
선점형 커널을 지원할 필요가 없는 것.
하지만 리눅스의 경우 소스가 공개되어 있담보니 워낙 여러 가지 버전이 나오게 되었습니다.
그 중 하나가 RTLinux라고 불리는 RTOS버전의 리눅스입니다.
RTLinux는 내부적으로 RTOS용 커널(OS코드)을 별도로 유지하고 기존의 리눅스를 마치 하나의 프로세스처럼 취급하는 방식.
그리고 이 '리눅스 프로세스'를 가장 낮은 우선순위에 두고 인터럽트가 발생하여 즉각적인 처리를 필요로 하는
인터럽트의 경우 RTOS커널에서 바로 처리하고 그렇지 않은 경우 '리눅스 프로세스'로 전달해 주는 방식.
물론 RTOS커널에서는 선점성을 지원하지 않는 리눅스 커널의 시스템 함수를 사용하지 않습니다.
그럼으로써 완벽한 선점형 커널이 되고 RTOS의 특성을 띠는 것.

세그먼테이션(Segmentation)
페이징이 논리적인 내용과 상관없이 일정한 크기로 구획을 나눈 것이라면,
세그먼테이션은 논리적인 단위로 구획을 나누는 방식.
세그먼테이션에선 페이징과 달리 나뉘는 구획의 크기가 일정하지 않고, 프로세스의 논리적인 구성에 따라 나뉜다.
세그먼테이션에서는 프로세스를 동일한 크기로 나누지 않습니다.
대신 논리적으로 의미가 있는 구획끼리 묶어서 나누게 됩니다.
예를 들어 코드 구간, 데이터 구간, 스택 구간 등 처럼 나누는 방식으로 구간을 한 덩어리로 묶어 구간 단위로
메모리에 맵핑하는 것.
모든 프로세스는 코드 구간, 데이터 구간 등의 크기가 대부분 제각각입니다.
따라서 이런 논리 구간 단위로 나누어 사용하다보니 외부 단편화 문제가 필연적으로 발생.
(대신 내부 단편화문제는 발생하지 않습니다만 외부 단편화가 더 큰 문제)
그리고 이런 구간은 페이징에서 나누는 구획 크기보다 훨씬 크게 됩니다.
코드 구간 전체를 하나의 구획 단위로 사용하게 되면 이 코드 전체가 메모리로 올라와야 하므로
동시에 메모리로 올라 올 수 있는 프로세스의 수가 적어진다.
결국 페이징 기법을 도입하게 된 결정적 단점이 세그먼테이션에서는 그대로 남아있다.

그러면 어느 경우에 세그먼테이션 기법이 필요할까?
80386이전까지만해도 세그먼테이션 기법을 사용했다.
윈도우즈와 같이 동시에 여러 프로그램이 실행되는 다중 프로그램 환경이 아니었고 메모리 크기도 작아서.
세그먼테이션을 사용하면 논리적인 단위로 구분해서 프로그래밍하기 용이합니다.
코드와 데이터 영역을 구분하고 이 영역의 구분을 위해 별도의 코드 세그먼트(CS) 레지스터와 데이터
세그먼트(DS)레지스터를 마련해두면, 프로그래머는 CS와 DS레지스터만 한 번 설정한 후 그 구간 안에서는
절대주소체계로 프로그램을 작성할 수 있습니다.
따라서 절대주소로 만들어진 프로그램이라 할지라도 이런 세그먼트 레지스터만 조절하면 얼마든지 임의의 메모리로
로드할 수 있는 것.
또 다른 장점은 논리적인 단위로 구획을 나누다 보니 메모리의 사용 용도 역시 논리적으로 제약을 둘 수 있다.
메모리의 코드 부분을 수행 도중 수정해 악용하는 경우를 방지할 수 있다.
페이징 기법에서는 페이지가 코드인지 데이터인지 알 수 없기 떄문에, 메모리의 용도에 따라
쓰기 금지 등의 제약을 둘 수 밖에 없는 반면, 세그먼테이션 기법에서는 코드, 데이터 등이 각각 한 덩이로 묶여
있으므로 그 용도에 따라 적절하게 메모리 액세스에 대해 차등 권한을 줄 수 있는 것.
만약 코드 세그먼트 부분에 해당하는 메모리를 수정하려 하면 CPU가 알아채고 에러를 발생시켜 프로그램을 보호할 수 있다.

예전 16비트 CPU시절에는 세그먼테이션이 이런 용도보다도 액세스 가능한 주소를 늘리기 위한 방법으로 활용.
16비트 레지스터로 64KB밖에 액세스할 수 없었다.
따라서 별도의 CS라고 불리는 코드 세그먼트 레지스터를 두어 CS레지스터와 PC레지스터(IP레지스터) 의 값을 조합해서
20비트의 물리 메모리 주소를 생성했었습니다.
1MB까지 메모리를 확장할 수 있었고, 특별한 모드를 사용하지 않는 한 사용 가능한 메모리도 640KB로 제한.
점점 메모리는 커지고, 다중 프로그램 OS가 등장하면서 80386부터는 페이징 기법을 도입.
하지만 완전하게 페이징 기법만 사용한 것이 아니라 세그먼테이션과 혼합한 방식을 사용했다.
CPU가 생성하는 논리 주소는 세그먼트 레지스터를 지정하는 인덱스와 나머지 부분으로 이루어져 있다.
일단 논리 주소가 생성되면 CPU는 이 주소의 세그먼트 레지스터 인덱스 부분을 참고해서 세그먼트에 관련된
내용을 용약해놓은 세그먼트 디스크립터라는 것을 찾습니다.
이 디스크립터 안에는 세그먼트가 가지는 권한이나 해당 세그먼트의 최대 크기 등 여러 논리적인 요소에 대한 정보를 담는다.
또한 페이징을 위한 주소를 생성할 수 있도록 세그먼트의 시작 주소가 담겨있습니다.
그러면 이 시작주소와 논리주소의 세그먼트 인덱스를 제외한 나머지 부분이 합쳐져 제 2의 논리 주소를 형성.
그리고 이 제 2의 논리 주소부터 페이징이 적용되기 시작한다.
이미 한번 세그먼트 디스크립터 테이블을 통해 CPU가 생성한 논리 주소의 논리적 타당성을 검사하였으므로
제 2논리주소부터는 논리적인 구분 없이 페이징 기법을 그대로 도입하여 적용하는 것.
이렇게 생성된 제2의 논리주소를 CPU가 생성한 논리주소와 구분하기위해 선형주소(Linear Address)라고 한다.
	┌───────────────────세그먼테이션(Segmentation)───────────────────┐
	|                                                               |
  ┌─|─>|세그먼트인덱스|오프셋|                                        | 
  |	|        |         └────────────────────────────┐               |
  | |    선택| |세그먼트디스크립터| 선택된 세그먼트의  ↓                |
  | |        └>|세그먼트디스크립터| ───────────────> +                |
  | |           ...                시작주소         |                |
  | └───────────────────────────────────────────────────────────────┘
  |논리주소         인스트럭션                       ↓선형주소
  └────────| CPU |<─────────|메모리|<──────────── 페이징(paging)
                  or 데이터        최종 물리 메모리 주소
CPU가 생성한 논리 주소가 우선 세그먼테이션을 거쳐 또 다른 논리 주소인 선형 주소로 변형되고 이 선형주소가
다시 페이징과정을 거쳐 최종적인 물리 메모리 주소로 변형되는 과정입니다.
두 번의 과정을 거치는 동안 세그먼테이션의 장점인 메모리 보호와 페이징의 장점인 외부 단편화 제거 및
많은 수의 프로세스 수용 등이 함께 적용됩니다.
반면 여러 과정을 거치다보니 최종 물리 주소 생성 때까지 걸리는 시간이 늘어납니다.
이를 위해 페이징의 TLBs나 세그먼테이션에서 사용하는 전용 세그먼트 레지스터를 마련해 성능 향상.
										 
*/