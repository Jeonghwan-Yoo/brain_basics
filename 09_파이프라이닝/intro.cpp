/*
파이프라이닝(Pipelining)의 개념?
각 단계 별로 결과값을 저장할 레지스터로 나눈 이유가 파이프라이닝.
CPU의 수행을 여러 단계로 나누어, 각 단계를 동시에 수행하는 것.
하나의 인스트럭션 수행이 완전히 끝날 때까지 기다리지 않고 인스트럭션 수행을 단계별로 나누어
여러 인스트럭션이 중첩되어 각 단계별로 진행되는 것.
이를 통해 이론적으로는 단계 수만큼 동시에 인스트럭션을 수행해 CPU속도를 증가.

파이프라이닝을 가로막는 방해 요소 중 대표적인 위험(Hazard)는 어떤 것이 있을까?
속도가 빨라지긴 하지만, 실제로는 여러 위험요소로 인해 이론만큼 속도가 나오진 않습니다.
대표적으로는 CPU의 구성상의 문제로 인한 구조적인 위험, 이전 단계의 데이터에 의존하게 되는 인스트럭션으로
인한 데이터 위험, 분기문의 경우 다음 인스트럭션이 결정나기까지 딜레이되는 분기 위험 등이 있다.

01 파이프라이닝
64비트라는 것은 데이터의 처리 단위를 나타내느 것으로 ALU가 반영되는 부분.
처리 비트 수가 늘어났다는 것은 단지 한번에 큰 수를 계산할 수 있고 메모리와 CPU간의 교환단위가 증가.
이러한 증가가 속도를 개선하긴 했지만 직접적으로 속도를 증가시키진 못함.
CPU의 동작 클럭 속도를 증가시키면 직접적으로 속도가 증가함.
증가율에 비례해서 동작 속도가 선형적으로 증가하는 가장 직접적이고 쉬운 방법.
클럭 속도를 높이면 그만큼 발열이나 전력소모가 높아지는데 미세 제조 공정으로 해결.
Intel은 클럭속도로만으로는 한계여서 RISC와 CISC의 조합된 형태의 CPU인 슈퍼 스칼라 방식.
매우 단순한 형태의 인스트럭션 Set과 모든 인스트럭션이 같은 길이로 이루어져 매우 체계적인 단계로 나뉨.
이 단계를 이용해 파이프라이닝이라는 기술을 사용할 수 있게 됨.
파이프라이닝이란 한 클럭당 수행할 수 있는 인스트럭션 개수를 늘리자는 생각에서 발생한 기술.
MIPS의 데이터 경로는 인스트럭션을 수행함에 있어 공통적인 부분 등을 묶어 여러 단계로 나눈 후의 하나의
인스트럭션 당 최소 3사이클 이상이 걸리는 멀티 사이클 구조였다.
대부분의 인스트럭션을 비슷한 부류로 묶어 비슷한 절차를 거리쳐, 비교적 명확하게 단계를 구분했다.
패치나 디코딩 과정은 모든 인스트럭션이 거치는 과정.
1)IF - 패치(Instruction Fetch)
2)ID - 디코딩(Instruction Decoding)
3)EX - 실행(Execution)
4)DM - 데이터 메모리 엑세스(Data Memory Access)
5)WB - 라이트백(Write Back)
만일 쉴 틈없이 첫번째 인스트럭션의 IF가 끝나자마자 바로 다음 인스트럭션의 IF를 시작하면 
최초의 인스트럭션만 5클럭에 걸쳐 끝나고 그 뒤엔 1클럭 뒤에 끝납니다.
IF ID EX DM WB       5
   IF ID EX DM WB    6
      IF ID EX DM WB 7

02 구조적인 위험(Structural Hazard)
CPU는 각 단계별로 사용하는 하드웨어가 있습니다.
IF단계에선 인스트럭션을 패치하기 위해 메모리를 액세스하고 DM단계에선 Load/Store등의 인스트럭션이
메모리에서 데이터를 읽거나 쓰기 위해 액세스합니다.
따라서 인스트럭션 메모리와 데이터 메모리가 하나로 이루어져 있다면 IF와 DM은 동시에 수행할 수 없습니다.
CPU에서 역시 하드웨어(리소스)를 둘러싼 충돌이 발생하게 되는데 이러한 충돌이 '구조적인 위험'이라고 합니다.
해결책은 같은 하드웨어를 사용하는 단계끼리 충돌이 발생하지 않도록 한쪽이 대기하거나 하드웨어 자체를
아예 따로 마련해 충돌 자체를 근본적으로 막는 수 밖에 없습니다.
메모리를 둘러싼 충돌은 인스트럭션과 데이터 간에는 연관성이 없으므로 별도로 나누어 충돌을 회피할 수 있다.
하지만 특정 레지스터에 기록한 값은 후에 다른 연산의 오퍼랜드가 되기도 하므로 읽는 레지스터와
쓰는 레지스터를 구분한다는 것은 근본적으로 불가능합니다.
다행히 레지스터는 CPU내부에 내장되어 있어 메모리 액세스에 비해 무척 빨라 한 단계 안에서 해결됨.
매 단계는 클럭에 의해 구분짓고, 클럭은 가장 긴 단계(주로 메모리액세스)에 맞추어 설정합니다.
그래서 ID는 단계의 전반부에 WB는 후반부에 나누어 실질적으로 겹치지 않게 합니다.
| IF |  |ID|| EX || DM ||WB|                   5
      | IF |  |ID|| EX || DM ||WB|             6
            | IF |  |ID|| EX || DM ||WB|       7
                  | IF |  |ID|| EX || DM ||WB| 8
물론 레지스터 액세스가 한 클럭의 절반 이하에 끝낼 수 있어야만 가능.
PC = PC + 4를 하기 위해 전용 Adder없이 ALU를 활용한 것을 다시 전용 Adder를 사용하도록 해야합니다.
왜냐면 IF단계에서 PC = PC + 4가 되는데 이 때 ALU를 사용하는 EX 단계 역시 수행중이기 때문.

03 분기 위험(Branch Hazard)
중간에 갑자기 예상치 못하게 다른 작업으로 전환되면서 발생한다 하여 분기 위험.
CPU에서는 분기문을 만났을 때 이런 현상이 발생합니다.
파이프라이닝이 진행 중인 CPU는 현재 인스트럭션이 끝나지 않은 생태에서도 끊임없이 다음 인스트럭션을
패치하고 디코딩하고 있습니다.
인스트럭션의 패치는 순차적으로 PC+4어드레스에서 이루어지는데, 중간에 실행 중인 인스트럭션이 분기문이고
분기 조건이 참일 경우 PC+4가 아닌 전혀 엉뚱한 분기 어드레스로 점프해야 합니다.
이런 경우 기존에 진행 중이던 다음 인스트럭션은 헛일이 된 것.
분기 여부를 결정하는 시기는 ALU의 Zero플래그를 통해 EX(실행)단계에서 판단합니다.
이를 앞당기기 위해 하드웨어를 추가해도 최소한 인스트럭션을 읽어오고 디코딩 단계를 지나야 판단 가능.
그러므로 최소 두 단계의 노력이 헛일이 될 수도 있습니다.
파이프라이닝을 정지하고 기다리면 시간이 너무 지체됩니다. 비효율적입니다.
그래서 일단 무조건 진행시킵니다. 그러다 분기가 생기면 폐기처분하고 다시 처음부터 가동시키는 것.
단, 이러한 분기문 판단이 DM이나 WB이전에 있어야만 중간에 취소된 인스트럭션으로 인한 오동작을 방지.
만일 잘못 실행되어 레지스터나 메모리에 기록되어도 ID나 EX에선 이미 분기조건이나 어드레스를 알게되 괜찮.
add $r1, $r2, $r3 | IF |  |ID|| EX || DM ||WB|
beg $r4, $r5, Exit      | IF |  |ID|| EX || DM ||WB|
sub $r6, $r7, $r8             | IF |  |ID|| EX || DM ||WB|
Exit: lw $r1, 123($t1)              | IF |  |ID|| EX || DM ||WB|
beq인스트럭션 이후 어느 인스트럭션을 실행하게 될지 여부는 최소한 beq의 ID단계가 끝나냐 알 수 있습니다.
그냥 기다리는 것보다 우선 바로 다음 인스트럭션을 정상적으로 패치해 둔 후 거짓이면 그대로 진행하면 되고,
참이어서 Exit로 점프하면 그 때 가서 다시 lw인스트럭션을 패치하면 됩니다.
손해보는 클럭 수는 한 클럭이지만 실제론 절반의 확률로 분기위험이 발생하므로 반 클럭의 패널티.

04 데이터 위험(Data Hazard)
두 개의 공정이 서로 의존 관계에 있어 시간적으로 뒤에 있는 공정의 결과가 나올 때까지 파이프라인이
중간에 멈추게 되는 경우 데이터 위험이 발생.
addi $r16, $zero ,50 #$r16 = 50
Again:
sub $r16, $r16, 1 #$r16 = $r16 - 1
bne $r16, $zero, Again #if ($r16 != 0) goto Again
이 코드는 풀스피드로 파이프라인을 돌릴 수 없습니다.
sub 인스트럭션의 ID단계는 addi의 WB가 끝날 때까지 기다렸다가 수행해야 합니다. 엉뚱한 값을 뺄 수 있으므로.
bne에서도 EX단계에서 $r16과 $zero의 뺄셈을 하기 위해서는 ID단계에서 미리 두 레지스터의 값을 읽어와야 합니다.
반면 sub는 WB단계가 되어서야 비로소 $r16에 결과값을 저장하므로 데이터 위험이 발생.
즉, addi인스트럭션이 결과를 WB단계에 가서야 $r16레지스터에 기로가는 반면 sub는 (3단계빠른)ID단계에서 필요합니다.
사실 addi의 EX단계에서 이미 계산되어 있습니다. 저장하는 단계가 WB일 뿐.
sub인스트럭션이 이 값을 필요로 하는 시점도 사실 EX단계이므로 그 전까지 받으면 됩니다.
EX단계의 출력단과 입력단 사이의 경로를 연결하여 데이터를 전달(포워딩)할 수 있게 하드웨어를 수정하면
addi의 실행 결과가 WB단계에 도달하기 전에 EX의 입력으로 들어갈 수 있습니다.
sub 인스트럭션이 addi가 $r16에 연산결과를 저장할 때까지 기다릴 필요가 없어짐.
이렇게 각 단계의 출력값을 다른 단계의 입력값으로 바로 전송해줄 수 있는 경로를 만드는 것을 데이터포워딩이라고 한다.
하지만 완벽하게 데이터 위험을 해결해주는 것은 아닙니다.
lw의 DM단계가 끝난 시점에서 이미 sub의 EX가 끝나므로, 어쩔수 없이 한단계 쉬어야 합니다.
lw $r16, 0($r3)    | IF |  |ID|| EX || DM ||WB|
sub $r16, $r16, 1        | IF |        |ID|| EX || DM ||WB|
                                          └메모리에서 데이터 로드완료하고 데이터 포워딩.

인스트럭션 재배치를 통한 스톨(stall)제거
lw인스트럭션에 이어 곧바로 저장할 레지스터를 액세스하는 인스트럭션이 올 경우 데이터 포워딩을 해도
한 클럭 동안 파이프라인을 정지시켜야 했습니다.
어떤 종류의 위험으로 인해 파이프라인이 멈추는 것을 스톨이 생겼다고 하는데 소프트웨어적으로도 해결가능합니다.
lw $r16, 0($r3) #$r16 = Mem[$r3]
sub $r16, $r16, 1 #$r16 = $r16 - 1
add $r15, $r14, $r13 #$r15 = $r14 + $r13
$r16레지스터를 공유하므로 데이터 위험이 발생하고 데이터 포워딩을 해도 한 번의 스톨이 발생.
사실 add는 두 인스트럭션과 연관성이 없습니다.
즉, 전혀 별개의 레지스터로 연산하기 때문에 add인스트럭션이 어느 곳에 위치하더라도 상관없습니다.
이를 착안해 add를 lw와 sub사이에 집어 넣으면 스톨없이 풀스피드로 파이프라인이 가동될 수 있습니다.
lw $r16, 0($r3)        | IF |  |ID|| EX || DM ||WB|
add $r15, $r14, $r13         | IF |  |ID|| EX || DM ||WB|
sub $r16, $r16, 1                  | IF |  |ID|| EX || DM ||WB|
                                              └메모리에서 데이터 로드완료하고 데이터 포워딩.
sub는 한 클럭 기다려야 하는데 상관없는 인스트럭션을 먼저 실행시켜 결과적으로 전체 스피드를 올림.
하지만 이런 일들은 컴파일러가 자동으로 해주기 때문에 편하게 프로그램을 만들면 됩니다.

*/